{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_imcoords_to_bbox(imcoords):\n",
    "    # imcoords는 문자열 형태의 좌표를 파싱하여 리스트로 변환\n",
    "    coords = list(map(float, imcoords.split(',')))\n",
    "    x_values = coords[0::2]  # 짝수 인덱스는 x 좌표\n",
    "    y_values = coords[1::2]  # 홀수 인덱스는 y 좌표\n",
    "    \n",
    "    # 좌표로부터 bbox의 중심 좌표(cx, cy), 너비(width), 높이(height) 계산\n",
    "    x_min = min(x_values)\n",
    "    x_max = max(x_values)\n",
    "    y_min = min(y_values)\n",
    "    y_max = max(y_values)\n",
    "    \n",
    "    cx = (x_min + x_max) / 2\n",
    "    cy = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    \n",
    "    return cx, cy, width, height\n",
    "\n",
    "def filter_and_modify_json(directory, output_directory):\n",
    "    # 지정된 디렉토리 내 모든 JSON 파일 확인\n",
    "    for filename in tqdm(os.listdir(directory), desc=\"Processing files\", unit=\"file\"):\n",
    "        if filename.endswith(\".json\"):\n",
    "            input_file_path = os.path.join(directory, filename).replace('\\\\', '/')\n",
    "            \n",
    "            with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "            \n",
    "            # 새로운 피처 저장 리스트\n",
    "            filtered_features = []\n",
    "\n",
    "            # 'features' 필드가 있는지 확인하고 반복\n",
    "            if 'features' in data:\n",
    "                for feature in data['features']:\n",
    "                    if 'properties' in feature:\n",
    "                        type_name = feature['properties'].get('type_name')\n",
    "                        \n",
    "                        # 'type_name'이 'ship(S)' 또는 'ship(L)'인 경우만 처리\n",
    "                        if type_name in ['ship(S)', 'ship(L)']:\n",
    "                            imcoords = feature['properties'].get('object_imcoords')\n",
    "                            if imcoords:\n",
    "                                # 좌표 변환 후 새로운 값 추가\n",
    "                                cx, cy, width, height = convert_imcoords_to_bbox(imcoords)\n",
    "                                feature['properties']['cx'] = cx\n",
    "                                feature['properties']['cy'] = cy\n",
    "                                feature['properties']['width'] = width\n",
    "                                feature['properties']['height'] = height\n",
    "                                \n",
    "                                # 기존 데이터와 함께 새로운 properties로 업데이트\n",
    "                                filtered_features.append(feature)\n",
    "\n",
    "            # 새로운 JSON 구조 생성\n",
    "            if filtered_features:\n",
    "                new_data = {\n",
    "                    \"type\": \"FeatureCollection\",\n",
    "                    \"features\": filtered_features\n",
    "                }\n",
    "\n",
    "                # 출력 경로 설정 (출력 폴더에 저장)\n",
    "                output_file_path = os.path.join(output_directory, filename).replace('\\\\', '/')\n",
    "                with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "                    json.dump(new_data, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "def check_for_other_classes(directory):\n",
    "    other_classes_found = False\n",
    "    other_classes = set()\n",
    "\n",
    "    # 지정된 디렉토리 내 모든 JSON 파일 확인\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(directory, filename).replace('\\\\', '/')\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "            \n",
    "            # 'features' 필드가 있는지 확인하고 반복\n",
    "            if 'features' in data:\n",
    "                for feature in data['features']:\n",
    "                    if 'properties' in feature:\n",
    "                        type_name = feature['properties'].get('type_name')\n",
    "                        \n",
    "                        # 'ship(S)' 또는 'ship(L)' 외의 다른 클래스가 있는지 확인\n",
    "                        if type_name not in ['ship(S)', 'ship(L)']:\n",
    "                            other_classes_found = True\n",
    "                            other_classes.add(type_name)\n",
    "\n",
    "    # 결과 출력\n",
    "    if other_classes_found:\n",
    "        print(\"다른 클래스가 발견되었습니다:\", other_classes)\n",
    "    else:\n",
    "        print(\"모든 JSON 파일이 'ship(S)' 또는 'ship(L)'만 포함하고 있습니다.\")\n",
    "        \n",
    "# Train\n",
    "input_directory = './train_objects_labels'  # 입력 JSON 파일들이 있는 폴더\n",
    "output_directory = './datasets/labels/train'  # 필터링 후 JSON 파일을 저장할 폴더\n",
    "\n",
    "# 출력 폴더가 없으면 생성\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# 필터링 및 변환 실행\n",
    "filter_and_modify_json(input_directory, output_directory)\n",
    "check_for_other_classes(output_directory)\n",
    "\n",
    "# valid\n",
    "input_directory = './vaildate_objects_labels'  # 입력 JSON 파일들이 있는 폴더\n",
    "output_directory = './datasets/labels/val'  # 필터링 후 JSON 파일을 저장할 폴더\n",
    "\n",
    "# 출력 폴더가 없으면 생성\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# 필터링 및 변환 실행\n",
    "filter_and_modify_json(input_directory, output_directory)\n",
    "check_for_other_classes(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네거티브 샘플 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "def create_empty_ship_json(input_directory, output_directory, num_empty_files=80):\n",
    "    # JSON 파일 목록에서 num_empty_files 개수만큼 무작위로 선택\n",
    "    json_files = [f for f in os.listdir(input_directory) if f.endswith(\".json\")]\n",
    "    selected_files = random.sample(json_files, min(num_empty_files, len(json_files)))\n",
    "    \n",
    "    # 배가 없는 빈 JSON 파일 생성\n",
    "    for filename in tqdm(selected_files, desc=\"Creating empty ship files\", unit=\"file\"):\n",
    "        empty_data = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"features\": []\n",
    "        }\n",
    "        # 원래 파일 이름을 그대로 사용하여 출력\n",
    "        output_file_path = os.path.join(output_directory, filename).replace('\\\\', '/')\n",
    "        \n",
    "        with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(empty_data, outfile, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "# .json 파일을 기반으로 .png 파일을 찾고, 해당 파일을 바로 복사하는 함수\n",
    "def get_and_copy_img(json_path, img_path, save_dir):\n",
    "    # save_dir이 없으면 디렉토리 생성\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # .json 파일을 기반으로 .png 파일을 찾아서 복사\n",
    "    for filename in tqdm(os.listdir(json_path), desc=\"Processing files\", unit=\"file\"):\n",
    "        # .json 파일명을 .png 파일명으로 변환\n",
    "        png_file = filename.replace('.json', '.png')\n",
    "        png_file = os.path.join(img_path, png_file).replace('\\\\', '/')\n",
    "        \n",
    "        # .png 파일이 존재하는지 확인하고, 존재하면 복사\n",
    "        if os.path.exists(png_file):\n",
    "            img = cv2.imread(png_file)\n",
    "            \n",
    "            cv2.imwrite(os.path.join(save_dir, png_file.split('/')[-1]), img)\n",
    "            # shutil.copy(png_file, save_dir)\n",
    "        else:\n",
    "            print(f\"Warning: {png_file} not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# .json 파일과 .png 파일 경로를 리스트로 반환하는 함수\n",
    "def get_img_json_list(json_path, img_path):\n",
    "    img_json_list = []\n",
    "    for filename in tqdm(os.listdir(json_path), desc=\"Processing files\", unit=\"file\"):\n",
    "        # .json 파일명을 .png 파일명으로 변환\n",
    "        json_file = os.path.join(json_path, filename).replace('\\\\', '/')\n",
    "        png_file = filename.replace('.json', '.png')\n",
    "        png_file = os.path.join(img_path, png_file).replace('\\\\', '/')\n",
    "\n",
    "        # .png 파일이 실제로 존재하는지 확인 후 리스트에 추가\n",
    "        if os.path.exists(png_file):\n",
    "            img_json_list.append([png_file, json_file])\n",
    "        else:\n",
    "            print(f\"Warning: {png_file} not found!\")\n",
    "\n",
    "    return img_json_list\n",
    "\n",
    "# 추출된 경로 리스트를 CSV 파일로 저장하는 함수\n",
    "def save_to_csv(data, output_csv):\n",
    "    # CSV 파일로 저장\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # 헤더 작성\n",
    "        writer.writerow([\"Image\", \"JSON\"])\n",
    "        # 데이터 작성\n",
    "        writer.writerows(data)\n",
    "        \n",
    "# Train\n",
    "label_dir = './datasets/labels/train'  # .json 파일들이 있는 디렉토리\n",
    "img_dir = './datasets/images/train'  # .png 파일들이 있는 디렉토리\n",
    "output_csv = 'train.csv'  # 경로 정보를 저장할 CSV 파일명\n",
    "\n",
    "# .json과 .png 경로 추출\n",
    "img_json_list = get_img_json_list(label_dir, img_dir)\n",
    "\n",
    "# 경로 정보를 CSV 파일로 저장\n",
    "save_to_csv(img_json_list, output_csv)\n",
    "\n",
    "# Valid\n",
    "label_dir = './datasets/labels/val'  # .json 파일들이 있는 디렉토리\n",
    "img_dir = './datasets/images/val'  # .png 파일들이 있는 디렉토리\n",
    "output_csv = 'valid.csv'  # 경로 정보를 저장할 CSV 파일명\n",
    "\n",
    "# .json과 .png 경로 추출\n",
    "img_json_list = get_img_json_list(label_dir, img_dir)\n",
    "\n",
    "# 경로 정보를 CSV 파일로 저장\n",
    "save_to_csv(img_json_list, output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라벨 데이터 생성(JSON -> CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# 유클리드 거리 계산 함수\n",
    "def euclidean_distance(p1, p2):\n",
    "    return np.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n",
    "\n",
    "def manhattan_distance(coords):\n",
    "    x_values = coords[0::2]  # 짝수 인덱스는 x 좌표\n",
    "    y_values = coords[1::2]  # 홀수 인덱스는 y 좌표\n",
    "    \n",
    "    # 좌표로부터 bbox의 중심 좌표(cx, cy), 너비(width), 높이(height) 계산\n",
    "    x_min = min(x_values)\n",
    "    x_max = max(x_values)\n",
    "    y_min = min(y_values)\n",
    "    y_max = max(y_values)\n",
    "\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    \n",
    "    return width, height\n",
    "\n",
    "\n",
    "# JSON 파일을 읽어들이는 함수 (BBox 좌표와 angle 포함)\n",
    "def get_bbox_from_json(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if 'features' in data:\n",
    "        for feature in data['features']:\n",
    "            if 'properties' in feature:\n",
    "                # object_imcoords를 파싱하여 좌표 추출\n",
    "                imcoords = feature['properties'].get('object_imcoords', '')\n",
    "                if imcoords:\n",
    "                    coords = list(map(float, imcoords.split(',')))\n",
    "\n",
    "                    # 맨해튼 거리 계산\n",
    "                    # width, height = manhattan_distance(coords)\n",
    "\n",
    "                    coords = np.array(coords).reshape(-1, 2)  # 2D 좌표로 변환\n",
    "\n",
    "                    # 중심 좌표 계산\n",
    "                    cx = np.mean(coords[:, 0])\n",
    "                    cy = np.mean(coords[:, 1])\n",
    "\n",
    "                    # 인접한 두 점으로부터 너비와 높이 계산\n",
    "                    width = euclidean_distance(coords[0], coords[1])\n",
    "                    height = euclidean_distance(coords[1], coords[2])\n",
    "\n",
    "                    # 각도 추출\n",
    "                    angle = feature['properties'].get('object_angle', 0.0)\n",
    "\n",
    "                    # 회전된 바운딩 박스 좌표 저장 (cx, cy, width, height, angle)\n",
    "                    results.append((cx, cy, width, height, angle))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_coords_from_json(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if 'features' in data:\n",
    "        for feature in data['features']:\n",
    "            if 'properties' in feature:\n",
    "                # object_imcoords를 파싱하여 좌표 추출\n",
    "                imcoords = feature['properties'].get('object_imcoords', '')\n",
    "                class_name = feature['properties'].get('type_name', '')\n",
    "                \n",
    "                if imcoords:\n",
    "                    coords = list(map(float, imcoords.split(',')))\n",
    "\n",
    "                    results.append((class_name,coords))\n",
    "    return results\n",
    "\n",
    "def save_coords_to_txt(coords_list, output_file, img_path):\n",
    "    with open(output_file, 'w') as f:\n",
    "        for coords in coords_list:\n",
    "            class_name, coords = coords\n",
    "            coords = np.array(coords) / 1024.0\n",
    "    \n",
    "             # 각 좌표값이 0 미만이면 0, 1 이상이면 1로 클리핑\n",
    "            coords = np.clip(coords, 0, 1)\n",
    "\n",
    "            x1, y1, x2, y2, x3, y3, x4, y4 = coords\n",
    "            \n",
    "            if class_name == 'ship(S)':\n",
    "                f.write(f\"0 {x1:.6f} {y1:.6f} {x2:.6f} {y2:.6f} {x3:.6f} {y3:.6f} {x4:.6f} {y4:.6f}\\n\")\n",
    "            elif class_name == 'ship(L)': \n",
    "                f.write(f\"1 {x1:.6f} {y1:.6f} {x2:.6f} {y2:.6f} {x3:.6f} {y3:.6f} {x4:.6f} {y4:.6f}\\n\")\n",
    "\n",
    "# 바운딩 박스 정보를 txt 파일로 저장하는 함수\n",
    "def save_bbox_to_txt(bbox_list, output_file, img_path):\n",
    "    with open(output_file, 'w') as f:\n",
    "        for bbox in bbox_list:\n",
    "            cx, cy, width, height, angle = bbox\n",
    "            cx, cy, width, height, angle = cx/1024, cy/1024, width/1024, height/1024, angle\n",
    "\n",
    "            # if cx < 0 or cy < 0 or width < 0 or height < 0 or cx > 1 or cy > 1 or width > 1 or height > 1:\n",
    "                # print(f\"Warning: {img_path} - bbox가 이미지 밖으로 벗어납니다.\")\n",
    "                # visualize_image_with_bbox(img_path, bbox_list)\n",
    "            if cx < 0 or cx > 1:\n",
    "                cx = max(0, min(cx, 1))\n",
    "            if cy < 0 or cy > 1:\n",
    "                cy = max(0, min(cy, 1))\n",
    "            if width < 0 or width > 1:\n",
    "                width = max(0, min(width, 1))\n",
    "            if height < 0 or height > 1:\n",
    "                height = max(0, min(height, 1))\n",
    "\n",
    "            f.write(f\"0 {cx:.6f} {cy:.6f} {height:.6f} {width:.6f} {angle:.6f}\\n\")\n",
    "            # f.write(f\"0 {cx:.6f} {cy:.6f} {height:.6f} {width:.6f}\\n\")\n",
    "\n",
    "\n",
    "def visualize_image_with_coords(image_path, coords_list):\n",
    "    img = Image.open(image_path)\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(img)\n",
    "\n",
    "    for class_name, coords in coords_list:\n",
    "        # coords: [x1, y1, x2, y2, x3, y3, x4, y4]\n",
    "        coords = np.array(coords)\n",
    "        coords = coords.reshape(4, 2)  # 4개의 좌표쌍 (x, y)으로 변환\n",
    "        \n",
    "        # 다각형 그리기 (4개의 좌표를 사용한 회전된 바운딩 박스)\n",
    "        polygon = patches.Polygon(coords, closed=True, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(polygon)\n",
    "        \n",
    "        # 클래스 이름 표시 (옵션)\n",
    "        cx, cy = np.mean(coords[:, 0]), np.mean(coords[:, 1])  # 중심 좌표\n",
    "        ax.text(cx, cy, class_name, color='blue', fontsize=12, ha='center')\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# CSV에서 이미지 경로와 JSON 경로를 불러오는 함수\n",
    "def load_csv(csv_path):\n",
    "    data = []\n",
    "    with open(csv_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # 헤더 스킵\n",
    "        for row in reader:\n",
    "            img_path, json_path = row\n",
    "            data.append((img_path, json_path))\n",
    "    return data\n",
    "\n",
    "# Train\n",
    "csv_path = 'train.csv'  # CSV 파일 경로\n",
    "data = load_csv(csv_path)  # 이미지와 JSON 경로 불러오기\n",
    "\n",
    "# 5개의 이미지와 바운딩 박스를 시각화하고, BBox 정보를 txt로 저장\n",
    "for i, (img_path, json_path) in enumerate(data):\n",
    "    if os.path.exists(img_path) and os.path.exists(json_path):\n",
    "        bbox_list = get_coords_from_json(json_path)  # JSON에서 BBox 추출\n",
    "        \n",
    "        # .txt 파일로 저장할 파일명 정의\n",
    "        output_file = json_path.replace('.json', '.txt')  # .json 파일명을 .txt로 변경\n",
    "        save_coords_to_txt(bbox_list, output_file, img_path)  # bbox 정보를 txt로 저장\n",
    "        \n",
    "        if i < 5:\n",
    "            # 이미지와 BBox 시각화\n",
    "            visualize_image_with_coords(img_path, bbox_list)\n",
    "            \n",
    "# Valid\n",
    "csv_path = 'valid.csv'  # CSV 파일 경로\n",
    "data = load_csv(csv_path)  # 이미지와 JSON 경로 불러오기\n",
    "\n",
    "# 5개의 이미지와 바운딩 박스를 시각화하고, BBox 정보를 txt로 저장\n",
    "for i, (img_path, json_path) in enumerate(data):\n",
    "    if os.path.exists(img_path) and os.path.exists(json_path):\n",
    "        bbox_list = get_coords_from_json(json_path)  # JSON에서 BBox 추출\n",
    "        \n",
    "        # .txt 파일로 저장할 파일명 정의\n",
    "        output_file = json_path.replace('.json', '.txt')  # .json 파일명을 .txt로 변경\n",
    "        save_coords_to_txt(bbox_list, output_file, img_path)  # bbox 정보를 txt로 저장\n",
    "        \n",
    "        if i < 5:\n",
    "            # 이미지와 BBox 시각화\n",
    "            visualize_image_with_coords(img_path, bbox_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 병합(AIHub + DataON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 기존 클래스 ID에서 새 클래스 ID로 매핑\n",
    "class_mapping = {\n",
    "    0: 0,  # motorboat -> ship(s)\n",
    "    1: 0,  # sailboat -> ship(s)\n",
    "    2: 0,  # tugboat -> ship(L)\n",
    "    3: 1,  # barge -> ship(L)\n",
    "    4: 0,  # fishing boat -> ship(s)\n",
    "    5: 1,  # ferry -> ship(L)\n",
    "    6: 1,  # container ship -> ship(L)\n",
    "    7: 1,  # oil tanker -> ship(L)\n",
    "    8: 1,  # drill ship -> ship(L)\n",
    "    9: 1,  # warship -> ship(L)\n",
    "}\n",
    "\n",
    "# 라벨과 이미지 원본 디렉터리\n",
    "original_labels_dir = './dataset2/labels'\n",
    "original_images_dir = './dataset2/images'\n",
    "\n",
    "# 새로 복사할 디렉터리\n",
    "new_labels_dir = './datasets/labels'\n",
    "new_images_dir = './datasets/images'\n",
    "\n",
    "# 폴더가 없는 경우 생성\n",
    "if not os.path.exists(new_labels_dir):\n",
    "    os.makedirs(new_labels_dir, exist_ok=True)\n",
    "if not os.path.exists(new_images_dir):\n",
    "    os.makedirs(new_images_dir, exist_ok=True)\n",
    "\n",
    "# 라벨 파일을 업데이트하여 새 디렉터리에 저장하는 함수\n",
    "def update_label_file(file_path, new_file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        original_class_id = int(parts[0])\n",
    "        if original_class_id in class_mapping:\n",
    "            new_class_id = class_mapping[original_class_id]\n",
    "            parts[0] = str(new_class_id)\n",
    "            new_line = ' '.join(parts)\n",
    "            new_lines.append(new_line)\n",
    "        else:\n",
    "            print(f\"경고: 클래스 ID {original_class_id}가 매핑에 없습니다.\")\n",
    "    \n",
    "    # 새 라벨 파일로 저장\n",
    "    os.makedirs(os.path.dirname(new_file_path), exist_ok=True)  # 하위 디렉터리 생성\n",
    "    with open(new_file_path, 'w') as file:\n",
    "        file.write('\\n'.join(new_lines))\n",
    "\n",
    "# 라벨 파일 업데이트 및 복사\n",
    "for root, dirs, files in os.walk(original_labels_dir):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.txt'):\n",
    "            old_file_path = os.path.join(root, filename)\n",
    "            # 기존 경로에서 새로운 라벨 경로로 변환 (dataset/labels/train, dataset/labels/val 등)\n",
    "            relative_path = os.path.relpath(old_file_path, original_labels_dir)\n",
    "            new_file_path = os.path.join(new_labels_dir, relative_path)\n",
    "            update_label_file(old_file_path, new_file_path)\n",
    "            print(f\"{new_file_path} 업데이트 완료\")\n",
    "\n",
    "# 이미지 파일 복사\n",
    "for root, dirs, files in os.walk(original_images_dir):\n",
    "    for filename in files:\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):  # 이미지 확장자에 따라 필터링\n",
    "            old_file_path = os.path.join(root, filename)\n",
    "            # 기존 경로에서 새로운 이미지 경로로 변환 (dataset/images/train, dataset/images/val 등)\n",
    "            relative_path = os.path.relpath(old_file_path, original_images_dir)\n",
    "            new_file_path = os.path.join(new_images_dir, relative_path)\n",
    "            os.makedirs(os.path.dirname(new_file_path), exist_ok=True)  # 하위 디렉터리 생성\n",
    "            shutil.copy2(old_file_path, new_file_path)\n",
    "            print(f\"{new_file_path} 이미지 복사 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yaml 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file 'data_augment.yaml' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "data = {\n",
    "    'train': './images/train',  # 학습 데이터셋 경로\n",
    "    'val': './images/val',  # 검증 데이터셋 경로\n",
    "    'nc': 2,  # 클래스 개수\n",
    "    'names': {\n",
    "        0: 'ship(S)',\n",
    "        1: 'ship(L)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the data to a YAML file\n",
    "with open('data_report.yaml', 'w') as file:\n",
    "    yaml.dump(data, file, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(\"YAML file 'data_augment.yaml' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import json\n",
    "# 하이퍼파라미터 튜닝\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo11x-obb.pt\")\n",
    "best_params = model.tune(\n",
    "    data=\"data_report.yaml\",\n",
    "    batch=16,\n",
    "    epochs=15,\n",
    "    iterations=50,\n",
    "    optimizer=\"AdamW\",\n",
    "    plots=True,\n",
    "    save=False,   # 모든 iteration에서 저장하지 않도록 설정\n",
    "    val=True,\n",
    "    lr0=0.001,\n",
    "    scale=0.2,\n",
    "    seed=44,\n",
    ")\n",
    "\n",
    "# 최적 하이퍼파라미터 저장\n",
    "with open(\"best_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f)\n",
    "print(\"Best parameters saved to best_params.json.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLO 모델 초기화\n",
    "model = YOLO(\"yolo11x-obb.pt\")\n",
    "results = model.train(\n",
    "    data = \"data_report.yaml\",\n",
    "    name = \"x_s512_best_args_report\",\n",
    "    seed=44,\n",
    "    epochs=20,\n",
    "    batch=12,\n",
    "    imgsz=512,\n",
    "    patience=15,\n",
    "    device=\"0\",\n",
    "    optimizer = \"AdamW\",\n",
    "    lr0= 0.00088,\n",
    "    lrf= 0.01134,   \n",
    "    momentum= 0.82858,\n",
    "    weight_decay= 0.0006,\n",
    "    warmup_epochs= 2.33952,\n",
    "    warmup_momentum= 0.58988,\n",
    "    box = 9.1,\n",
    "    cls= 0.56241,\n",
    "    dfl= 1.36767,\n",
    "    hsv_h= 0.01707,\n",
    "    hsv_s= 0.68688,\n",
    "    hsv_v= 0.28102,\n",
    "    degrees= 0.0,\n",
    "    translate= 0.11263,\n",
    "    shear= 0.0,\n",
    "    perspective= 0.0,\n",
    "    flipud= 0.45936,\n",
    "    fliplr= 0.46892,\n",
    "    bgr= 0.1,\n",
    "    mosaic= 0.828,\n",
    "    mixup= 0.0,\n",
    "    copy_paste= 0.0,\n",
    "    scale = 0.2,\n",
    "    dropout = 0.3,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 데이터 전처리, 추론 및 후처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True' \n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # 이미지 파일이 손상되었을 때 에러 발생 방지\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.ops import nms_rotated\n",
    "\n",
    "\n",
    "def get_imglist(dir=\"/workspace/dataset/\"):\n",
    "    imglist = [os.path.join(dir, f).replace(\"\\\\\", \"/\") for f in os.listdir(dir) if f.endswith(('.png', '.npy'))]\n",
    "    return imglist\n",
    "\n",
    "\n",
    "def create_temp_dir(base_dir='./temp_cropped_patches'):\n",
    "    \n",
    "    # 임시 폴더가 이미 존재하면 삭제하고 새로 생성\n",
    "    if os.path.exists(base_dir):\n",
    "        shutil.rmtree(base_dir)\n",
    "    os.makedirs(base_dir)\n",
    "    return base_dir\n",
    "\n",
    "\n",
    "def cluster_and_crop(image_path, k=3, size=1024, crop_num=43, threshold=0.7):\n",
    "    # 이미지 로드 및 리사이즈\n",
    "    img = Image.open(image_path)\n",
    "    img_np = np.array(img)\n",
    "    img_np = cv2.resize(img_np, (size, size), interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    \n",
    "    # 이미지 데이터를 준비 (픽셀 수, 3) 형태로 변형\n",
    "    img_data = img_np.reshape((-1, 3))\n",
    "    img_data = np.float32(img_data)\n",
    "\n",
    "    # K-Means 적용\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    _, labels, centers = cv2.kmeans(img_data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # 클러스터링 결과를 이미지로 변환\n",
    "    centers = np.uint8(centers)\n",
    "    segmented_img = centers[labels.flatten()]\n",
    "    segmented_img = segmented_img.reshape(img_np.shape)\n",
    "\n",
    "    # 검은색에 가장 가까운 클러스터 찾기\n",
    "    black_cluster_index = np.argmin(np.linalg.norm(centers, axis=1))  # 가장 작은 RGB 값이 검은색\n",
    "    \n",
    "    # crop 영역 추출\n",
    "    num_patches = []\n",
    "    crop_size = segmented_img.shape[1] // crop_num\n",
    "    for i in range(crop_num):\n",
    "        for j in range(crop_num):\n",
    "            \n",
    "            crop_img = segmented_img[i * crop_size:(i + 1) * crop_size, j * crop_size:(j + 1) * crop_size]\n",
    "\n",
    "            # 검은색 클러스터 비율 확인\n",
    "            cluster_0_value = centers[black_cluster_index]\n",
    "            cluster_0_mask = np.all(crop_img == cluster_0_value, axis=-1)\n",
    "            if np.mean(cluster_0_mask) > threshold:\n",
    "                num_patches.append((i, j))\n",
    "\n",
    "    \n",
    "    return num_patches\n",
    "\n",
    "def save_cropped_patches_as_numpy(image_path, \n",
    "                                  crop_size, \n",
    "                                  resize_size,\n",
    "                                  cluster_img_size,\n",
    "                                  cluster_threshold,\n",
    "                                  save_dir,\n",
    "                                  is_cluster):\n",
    "    image_name = os.path.basename(image_path)\n",
    "    print(f\"Processing {image_name}\")\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    image_width, image_height = image.size\n",
    "    \n",
    "    if is_cluster:\n",
    "        print(\"Procssing Clustering...\",end=\"\")\n",
    "        num_patches = cluster_and_crop(image_path, \n",
    "                                    k=3, \n",
    "                                    size=cluster_img_size, \n",
    "                                    crop_num=(image_width + crop_size - 1) // crop_size, \n",
    "                                    threshold=cluster_threshold)\n",
    "        print(\"Done. \")\n",
    "    else:\n",
    "        num_patches = [(i, j) for i in range((image_width + crop_size - 1) // crop_size) for j in range((image_height + crop_size - 1) // crop_size)]\n",
    "        \n",
    "    for i, j in tqdm(num_patches):\n",
    "        top_left_x = i * crop_size\n",
    "        top_left_y = j * crop_size\n",
    "        bottom_right_x = min(top_left_x + crop_size, image_width)\n",
    "        bottom_right_y = min(top_left_y + crop_size, image_height)\n",
    "        \n",
    "        if bottom_right_x - top_left_x < crop_size:\n",
    "            top_left_x = max(image_width - crop_size, 0)\n",
    "            bottom_right_x = image_width\n",
    "        if bottom_right_y - top_left_y < crop_size:\n",
    "            top_left_y = max(image_height - crop_size, 0)\n",
    "            bottom_right_y = image_height\n",
    "        \n",
    "        cropped_image = image.crop((top_left_x, top_left_y, bottom_right_x, bottom_right_y))\n",
    "        cropped_image = cropped_image.resize((resize_size, resize_size), resample=Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # 기존 코드에서 cropped_image를 numpy 배열로 변환\n",
    "        # OpenCV를 사용하여 리사이즈\n",
    "        # cropped_image = np.array(cropped_image)\n",
    "        # cropped_image = cv2.resize(cropped_image, (resize_size, resize_size), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "        # NumPy 배열로 저장\n",
    "        crop_filename = f\"{os.path.splitext(image_name)[0]}_{top_left_x}_{top_left_y}.npy\"  # NumPy로 저장\n",
    "        crop_path = os.path.join(save_dir, crop_filename)\n",
    "        np.save(crop_path, np.array(cropped_image, dtype=np.uint8))  # NumPy 배열로 저장 (dtype 명시)\n",
    "\n",
    "\n",
    "    del image\n",
    "\n",
    "def load_numpy_image(npy_path):\n",
    "    return np.load(npy_path)\n",
    "\n",
    "    \n",
    "class CroppedPatchDataset(Dataset):\n",
    "    def __init__(self, crop_image_paths, resize_size):\n",
    "        self.crop_image_paths = crop_image_paths\n",
    "        self.transform = transforms.ToTensor()\n",
    "        self.resize_size = resize_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.crop_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        crop_image_path = self.crop_image_paths[idx]\n",
    "        try:\n",
    "            cropped_image = load_numpy_image(crop_image_path)\n",
    "            cropped_image_tensor = self.transform(cropped_image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {crop_image_path}: {e}\")\n",
    "            return None  # 이미지 로드 실패 시 None 반환\n",
    "\n",
    "        # 패치의 위치 정보를 반환\n",
    "        image_name = os.path.basename(crop_image_path)\n",
    "        name_parts = image_name.split('_')\n",
    "        top_left_x = int(name_parts[-2])\n",
    "        top_left_y = int(name_parts[-1].split('.')[0])\n",
    "        position = torch.tensor([top_left_x, top_left_y])\n",
    "\n",
    "        original_image_name = '_'.join(name_parts[:-2]) + '.png'\n",
    "\n",
    "        return {\n",
    "            'image_name': original_image_name,\n",
    "            'image': cropped_image_tensor,\n",
    "            'top_left_position': position\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))  # None 제거\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "def run_model(image_names, images, positions, model, scale_factor, device,result):\n",
    "    # 모델 예측을 GPU에서 수행\n",
    "    preds = model.predict(images, conf=0.15, save=False, device=device)  # 예측 결과: [batch_size]\n",
    "\n",
    "    for img_name, pred, pos in zip(image_names, preds, positions):\n",
    "        if img_name not in result:\n",
    "            result[img_name] = []\n",
    "\n",
    "        top_left_x, top_left_y = pos[0].item(), pos[1].item()\n",
    "\n",
    "        # pred를 반복문 전에 CPU로 이동\n",
    "        pred = pred.cpu()\n",
    "\n",
    "        # 좌표 변환 및 conf 값 포함하여 저장\n",
    "        for i in range(len(pred)):\n",
    "            bbox = pred.obb.xywhr[i]  # [x, y, w, h, r]\n",
    "            confidence = pred.obb.conf[i]  # confidence 값\n",
    "\n",
    "            # bbox가 비어 있는 경우 해당 항목을 넘김\n",
    "            if len(bbox) == 0:\n",
    "                continue\n",
    "\n",
    "            # 예측된 좌표를 원본 이미지 좌표로 변환\n",
    "            x = bbox[0].item() * scale_factor + top_left_x\n",
    "            y = bbox[1].item() * scale_factor + top_left_y\n",
    "            w = bbox[2].item() * scale_factor\n",
    "            h = bbox[3].item() * scale_factor\n",
    "            r = bbox[4].item()  # 각도 값은 변환 불필요\n",
    "\n",
    "            # 변환된 좌표와 confidence를 결과 리스트에 추가\n",
    "            result[img_name].append({\n",
    "                'xywhr': [x, y, w, h, r],\n",
    "                'conf': confidence.item()\n",
    "            })\n",
    "            \n",
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.ops import nms_rotated\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 경로 설정\n",
    "directory_path = '/workspace/dataset/'\n",
    "# directory_path = './'\n",
    "base_dir = './temp_cropped_patches'\n",
    "img_list = get_imglist(directory_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 모델 설정\n",
    "model_name = \"./runs/obb/x_s512_best_args_report/weights/best.pt\"\n",
    "crop_size = 256\n",
    "resize_size = 512\n",
    "cluster_img_size = 1024\n",
    "cluster_threshold = 0.0\n",
    "batch_size = 32*1024*1024 // resize_size**2  \n",
    "divide_num = 54  # 원하는 분할 수로 설정\n",
    "\n",
    "model = YOLO(model_name)\n",
    "\n",
    "result = {}  # 최종 결과를 저장할 딕셔너리\n",
    "\n",
    "length = len(img_list)\n",
    "img_list_chunks = [img_list[i:i + length // divide_num] for i in range(0, length, length // divide_num)]\n",
    "\n",
    "for chunk_idx, img_chunk in enumerate(img_list_chunks):\n",
    "    # 임시 폴더 생성\n",
    "    temp_dir = create_temp_dir(base_dir=base_dir)\n",
    "    print(f\"Processing chunk {chunk_idx + 1}/{len(img_list_chunks)}\")\n",
    "\n",
    "    # 현재 청크의 이미지별 결과 리스트 초기화\n",
    "    for image_path in img_chunk:\n",
    "        image_name = os.path.basename(image_path)\n",
    "        result[image_name] = []\n",
    "\n",
    "    # 모든 이미지를 크롭하여 임시 폴더에 저장\n",
    "    for image_path in img_chunk:\n",
    "        image_name = os.path.basename(image_path)\n",
    "        print(f\"Cropping image: {image_name}\")\n",
    "        # 패치 저장 시 일관된 이름 지정\n",
    "        save_cropped_patches_as_numpy(image_path, \n",
    "                                          crop_size, \n",
    "                                          resize_size, \n",
    "                                          cluster_img_size,\n",
    "                                          cluster_threshold,\n",
    "                                          temp_dir,\n",
    "                                          is_cluster=False)\n",
    "\n",
    "    # 임시 폴더 내의 모든 패치 이미지 리스트 가져오기\n",
    "    temp_list = get_imglist(temp_dir)\n",
    "\n",
    "    # 데이터셋 및 DataLoader 설정\n",
    "    dataset = CroppedPatchDataset(temp_list, resize_size=resize_size)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=0)  # 필요에 따라 num_workers 조정\n",
    "\n",
    "    for batch in dataloader:\n",
    "        images = batch['image']\n",
    "        positions = batch['top_left_position']\n",
    "        patch_image_names = batch['image_name']\n",
    "\n",
    "        # 모델 실행 및 결과 저장\n",
    "        run_model(patch_image_names, images, positions, model, crop_size / resize_size, device, result)\n",
    "\n",
    "    # 현재 청크의 모든 이미지에 대해 NMS 적용\n",
    "    for image_path in img_chunk:\n",
    "        image_name = os.path.basename(image_path)\n",
    "        per_image_result = result[image_name]\n",
    "        if per_image_result:\n",
    "            # boxes와 scores 추출\n",
    "            boxes = torch.tensor([pred['xywhr'] for pred in per_image_result])\n",
    "            scores = torch.tensor([pred['conf'] for pred in per_image_result])\n",
    "\n",
    "            # NMS 적용\n",
    "            keep_indices = nms_rotated(boxes, scores, threshold=0.45)\n",
    "\n",
    "            # NMS 결과를 최종적으로 업데이트\n",
    "            result[image_name] = [per_image_result[i] for i in keep_indices]\n",
    "\n",
    "    # 쿠다 캐시 제거 및 불필요한 메모리 제거\n",
    "    torch.cuda.empty_cache()\n",
    "    del dataset\n",
    "    del dataloader\n",
    "    # 임시 폴더 삭제\n",
    "    shutil.rmtree(temp_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "# 저장할 CSV 경로\n",
    "csv_file = \"./submission.csv\"\n",
    "data = []  # CSV에 저장할 데이터를 담을 리스트\n",
    "\n",
    "# 이미지 이름별로 데이터 변환\n",
    "for image_name, predictions in result.items():\n",
    "    if not predictions:\n",
    "        continue\n",
    "    \n",
    "    # 각 예측 결과를 변환하여 data 리스트에 추가\n",
    "    for pred in predictions:\n",
    "        cx, cy, width, height, angle = pred['xywhr']\n",
    "        \n",
    "        # 각도 변환: 라디안 -> 도(degrees)\n",
    "        angle_deg = math.degrees(angle)\n",
    "        if angle_deg < 0:\n",
    "            angle_deg += 360\n",
    "        \n",
    "        # 예측 결과를 리스트로 추가\n",
    "        data.append([image_name, cx, cy, width, height, angle_deg])\n",
    "\n",
    "# CSV 파일로 저장\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # CSV의 헤더 작성\n",
    "    writer.writerow(['image_name', 'cx', 'cy', 'width', 'height', 'angle'])\n",
    "    \n",
    "    # 각 행을 작성\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV 파일 '{csv_file}'이(가) 성공적으로 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import aifactory.score as aif\n",
    "import time\n",
    "\n",
    "t = time.time()\n",
    "aif.submit(model_name=\"top_256_512_00\",\n",
    "           key=\"128fd22e-34e1-4e7a-b9c9-3423c2e859ce\")\n",
    "print(\"time:\", time.time() - t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
