{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860fe2dc",
   "metadata": {},
   "source": [
    "## 위성영상을 활용한 선박 탐지 AI 경진대회 제출 스크립트\n",
    "\n",
    "**주의1: 반드시 본 파일을 이용하여 제출을 수행해야 하며 파일의 이름은 task.ipynb로 유지되어야 합니다.**\n",
    "\n",
    "**주의2: 본 파일의 경로는 제출하시는 모든 모델, 스크립트 구성의 최상위 경로에 위치하고 있어야 합니다.**\n",
    "\n",
    "- 작성하신 추론용 코드를 본 스크립트 내에 삽입하는 것으로 결과 제출을 수행할 수 있습니다.\n",
    "- 테스트 데이터가 제공되지 않는 대회로, 안내된 경로를 파라미터로 입력하였을 때 모델이 경로 내의 이미지를 읽어서 추론을 수행할 수 있도록 구성되어야 합니다.\n",
    "\n",
    "코드는 크게 5가지 파트로 구성되며, 해당 파트의 특성을 지켜서 내용을 편집하시면 되겠습니다.\n",
    "1. 제출용 aifactory 라이브러리 설치 \n",
    "2. 기타 필요한 라이브러리 설치\n",
    "3. 추론 스크립트 구성\n",
    "4. aifactory 라이브러리를 이용한 제출 수행\n",
    "5. 기타 참고사항\n",
    "\n",
    "※ 가능하면 제출시에는 사용할 모델 및 weight를 제외한 나머지 데이터를 배제하고 제출하는 편을 권장합니다\n",
    "- 파일 크기 감소 → 업로드 시간 감소 → 전체 추론 수행 및 결과 확인 소요 시간 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6760b6-7d26-4f5c-980c-bfe9222a605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ultralytics in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (8.3.5)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ultralytics) (3.7.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (2.28.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ultralytics) (1.11.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ultralytics) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ultralytics) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (2.0.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.41.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a2646",
   "metadata": {},
   "source": [
    "### 1. 제출용 aifactory 라이브러리 설치\n",
    "#### 결과 전송에 필요하므로 아래와 같이 aifactory 라이브러리가 반드시 최신버전으로 설치될 수 있게끔 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c026fc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: aifactory in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pipreqs in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from aifactory) (0.5.0)\n",
      "Requirement already satisfied: ipynbname in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from aifactory) (2024.1.0.0)\n",
      "Requirement already satisfied: gdown in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from aifactory) (5.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from aifactory) (2.28.2)\n",
      "Requirement already satisfied: IPython in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from aifactory) (8.12.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from gdown->aifactory) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from gdown->aifactory) (3.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from gdown->aifactory) (4.65.0)\n",
      "Requirement already satisfied: ipykernel in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ipynbname->aifactory) (6.19.2)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from IPython->aifactory) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from IPython->aifactory) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from IPython->aifactory) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from IPython->aifactory) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from IPython->aifactory) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from IPython->aifactory) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from IPython->aifactory) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from IPython->aifactory) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from IPython->aifactory) (5.7.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from IPython->aifactory) (0.4.6)\n",
      "Requirement already satisfied: docopt==0.6.2 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from pipreqs->aifactory) (0.6.2)\n",
      "Requirement already satisfied: nbconvert<8.0.0,>=7.11.0 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from pipreqs->aifactory) (7.16.4)\n",
      "Requirement already satisfied: yarg==0.1.9 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from pipreqs->aifactory) (0.1.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from requests->aifactory) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from requests->aifactory) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from requests->aifactory) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from requests->aifactory) (2023.7.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from jedi>=0.16->IPython->aifactory) (0.8.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (3.1.2)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (5.3.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2.1.1)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (5.10.4)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (23.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->aifactory) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4->gdown->aifactory) (2.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (1.5.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (8.1.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (1.5.6)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (6.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from requests->aifactory) (1.7.1)\n",
      "Requirement already satisfied: executing in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from stack-data->IPython->aifactory) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from stack-data->IPython->aifactory) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from stack-data->IPython->aifactory) (0.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->ipynbname->aifactory) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from jupyter-core>=4.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2.5.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\programdata\\anaconda3\\envs\\um\\lib\\site-packages (from jupyter-core>=4.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (305.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (4.23.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\pook0\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.20.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U aifactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c7af5",
   "metadata": {},
   "source": [
    "### 2. 기타 필요한 라이브러리 설치\n",
    "#### 사전 제공되지 않은 라이브러리 가운데 필요한 것이 있는 경우 여기에 설치 명령을 넣습니다\n",
    "**예)** !pip install tensorflow[and-cuda]      *# PyTorch 대신 GPU를 사용하는 tensorflow를 설치하는 경우*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5bf3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade5aeb9",
   "metadata": {},
   "source": [
    "### 3. 추론 스크립트 구성\n",
    "#### 추론 스크립트 편집 시 주의사항\n",
    "\n",
    "1. 전체 추론 실행 코드를 삽입, 테스트셋에 대하여 추론을 수행하고 결과를 지정된 파일명으로 저장하도록 구성\n",
    "   - 필요한 경우 현재 위치(제목 3.이하, 제목 4.이전)에서 코드를 여러 셀로 나누어 저장해도 무방합니다.\n",
    "   - 결과 파일은 현재 경로에 **submission.csv**로 저장합니다.\n",
    "3. 제출 폴더 및 모델 소스코드 내부의 경로는 **./폴더명 또는 ./파일명**으로 **상대 경로**를 지정합니다.\n",
    "4. 테스트셋 경로는 **/workspace/dataset** 입니다. \n",
    "5. 저장할 파일명과 양식에 유의합니다.\n",
    "   - 대회 페이지 [데이터]탭 참조\n",
    "   - 파일 양식 가운데 image_name 열은 경로명을 제외하고 정확히 파일명(abcd.jpg)만 들어가야 하므로 코드 작성 시에 참고 부탁드립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e1d20",
   "metadata": {},
   "source": [
    "1. 이미지 리스트를 불러온다.\n",
    "2. 리스트에서 이미지 한장을 Image.open()으로 열어본다.\n",
    "3. 연 이미지를 모델에 맞게 crop한다.\n",
    "4. crop한 이미지를 텐서로 작성해 버퍼에 저장한다.\n",
    "5. crop한 뒤 원래 위치를 보정해서 작성하기 위해 원래 이미지에서의 좌상단 위치도 함께 작성해 버퍼에 저장한다.\n",
    "6. 버퍼에 저장한 crop이미지와 위치를 딕셔너리 형태로 작성한다.\n",
    "\n",
    "'image_name': 이미지의 원래 이름.png,'image': 이미지 텐서, 'top_left_position':해당 이미지의 좌상단 좌표\n",
    "데이터로더의 출력은 [batch, 3, crop_size, crop_size]의 이미지 텐서,[batch,1]의 이미지 이름 [batch, 2]의 좌상단 좌표 텐서이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7197e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# 이미지 목록을 가져오는 함수\n",
    "def get_imglist(dir=\"./sample/img\"):\n",
    "    imglist = [os.path.join(dir, f).replace(\"\\\\\", \"/\") for f in os.listdir(dir) if f.endswith('.png')]\n",
    "    return imglist\n",
    "\n",
    "class CroppedImageDataset(Dataset):\n",
    "    def __init__(self, image_list, crop_size, color_stats_file):\n",
    "        self.image_list = image_list\n",
    "        self.crop_size = crop_size\n",
    "        self.transform = transforms.ToTensor()  # 이미지 -> 텐서 변환\n",
    "        \n",
    "        # 색상 통계 정보 불러오기\n",
    "        color_stats = np.load(color_stats_file)\n",
    "        self.mean = color_stats['mean']\n",
    "        self.std = color_stats['std']\n",
    "        self.color_transform = transforms.Normalize(mean=self.mean.tolist(), std=self.std.tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_list[idx]\n",
    "        image_name = os.path.basename(image_path)\n",
    "\n",
    "        # 이미지 열기\n",
    "        image = Image.open(image_path)\n",
    "        image_width, image_height = image.size\n",
    "        # image = np.array(image)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # image = cv2.imread(image_path)\n",
    "        # if image is not None:\n",
    "        # image_height, image_width = image.shape[:2]\n",
    "        \n",
    "\n",
    "        # 전체 크롭 이미지 개수 계산\n",
    "        num_crops_x = (image_width + self.crop_size - 1) // self.crop_size\n",
    "        num_crops_y = (image_height + self.crop_size - 1) // self.crop_size\n",
    "        total_crops = num_crops_x * num_crops_y\n",
    "\n",
    "        # 크롭할 영역의 좌상단 좌표를 슬라이딩 윈도우 방식으로 구함\n",
    "        cropped_images = []\n",
    "        positions = []\n",
    "        last_cropped_image_info = None  # 마지막 크롭된 이미지 정보 저장\n",
    "\n",
    "        for top_left_x in range(0, image_width, self.crop_size):\n",
    "            for top_left_y in range(0, image_height, self.crop_size):\n",
    "                # 마지막 부분에서 경계 넘지 않도록 마지막 부분을 맞춤\n",
    "                bottom_right_x = min(top_left_x + self.crop_size, image_width)\n",
    "                bottom_right_y = min(top_left_y + self.crop_size, image_height)\n",
    "\n",
    "                # 이미지 경계 부분에 대해 크롭 영역을 이동시킴\n",
    "                if bottom_right_x - top_left_x < self.crop_size:\n",
    "                    top_left_x = image_width - self.crop_size\n",
    "                    bottom_right_x = image_width\n",
    "\n",
    "                if bottom_right_y - top_left_y < self.crop_size:\n",
    "                    top_left_y = image_height - self.crop_size\n",
    "                    bottom_right_y = image_height\n",
    "\n",
    "                # 크롭한 이미지 자르기\n",
    "                # cropped_image = image.crop((top_left_x, top_left_y, bottom_right_x, bottom_right_y))\n",
    "                cropped_image = image[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "\n",
    "                # 크롭한 이미지를 resize\n",
    "                resize = self.crop_size * 4\n",
    "                cropped_image = cv2.resize(cropped_image, (resize, resize))\n",
    "\n",
    "                # 크롭한 이미지를 텐서로 변환\n",
    "                cropped_image_tensor = self.transform(cropped_image)\n",
    "                # cropped_image_tensor = self.color_transform(cropped_image_tensor)\n",
    "\n",
    "                # 크롭한 이미지와 좌상단 좌표 저장\n",
    "                cropped_images.append(cropped_image_tensor)\n",
    "                positions.append(torch.tensor([top_left_x, top_left_y]))\n",
    "\n",
    "                # 마지막 크롭된 이미지의 정보 저장 (좌표와 실제 크기)\n",
    "                last_cropped_image_info = {\n",
    "                    'image_tensor': cropped_image_tensor,\n",
    "                    'top_left': (top_left_x, top_left_y),\n",
    "                    'bottom_right': (bottom_right_x, bottom_right_y),\n",
    "                    'size': (bottom_right_x - top_left_x, bottom_right_y - top_left_y)  # 실제 크기 저장\n",
    "                }\n",
    "\n",
    "        # 이미지 이름, 크롭한 이미지 텐서 목록, 각 이미지의 좌상단 좌표 및 크롭 개수 반환\n",
    "        return {\n",
    "            'image_name': image_name,\n",
    "            'images': cropped_images,  # 잘라낸 이미지 텐서 리스트\n",
    "            'top_left_positions': positions,  # 각 이미지의 좌상단 좌표 리스트\n",
    "            'total_crops': total_crops,  # 총 크롭 이미지 개수\n",
    "            'last_cropped_image_info': last_cropped_image_info  # 마지막 크롭 이미지 정보\n",
    "        }\n",
    "\n",
    "# 배치 데이터를 처리하는 collate_fn 정의\n",
    "def collate_fn(batch, batch_size):\n",
    "    all_image_names = []\n",
    "    all_images = []\n",
    "    all_top_left_positions = []\n",
    "    total_crops = 0  # 전체 크롭 이미지 개수를 추적\n",
    "    last_cropped_images_info = []  # 마지막 크롭 이미지 정보 추적\n",
    "\n",
    "    for item in batch:\n",
    "        image_names = [item['image_name']] * len(item['images'])  # 각 이미지에 같은 이름을 붙임\n",
    "        all_image_names.extend(image_names)\n",
    "        all_images.extend(item['images'])  # 이미지를 리스트에 추가\n",
    "        all_top_left_positions.extend(item['top_left_positions'])  # 좌상단 좌표 추가\n",
    "        total_crops += item['total_crops']  # 총 크롭 개수 계산\n",
    "        last_cropped_images_info.append(item['last_cropped_image_info'])  # 마지막 크롭 정보 추가\n",
    "\n",
    "    # 전체 이미지 목록을 batch_size 크기씩 나눠서 반환\n",
    "    batch_start = 0\n",
    "    while batch_start < len(all_images):\n",
    "        images_batch = torch.stack(all_images[batch_start:batch_start + batch_size])  # batch_size만큼 이미지 묶기\n",
    "        positions_batch = torch.stack(all_top_left_positions[batch_start:batch_start + batch_size])  # batch_size만큼 좌표 묶기\n",
    "        names_batch = all_image_names[batch_start:batch_start + batch_size]  # batch_size만큼 이미지 이름 묶기\n",
    "        \n",
    "        batch_start += batch_size\n",
    "        \n",
    "        yield {\n",
    "            'image_names': names_batch,  # 이미지 이름 리스트\n",
    "            'images': images_batch,  # [batch_size, 3, crop_size, crop_size]\n",
    "            'top_left_positions': positions_batch,  # [batch_size, 2]\n",
    "            'total_crops': total_crops,  # 전체 크롭 이미지 개수\n",
    "            'last_cropped_images_info': last_cropped_images_info  # 마지막 크롭 이미지 정보\n",
    "        }\n",
    "\n",
    "# dataset = CroppedImageDataset(img_list, crop_size)\n",
    "\n",
    "# # DataLoader에서 batch_size를 16으로 설정\n",
    "# batch_size = 32\n",
    "# dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=lambda x: collate_fn(x, batch_size))\n",
    "\n",
    "# # 배치 데이터 확인 및 검증\n",
    "# for batch in dataloader:\n",
    "#     total_images = 0  # 전체 크롭 이미지 개수를 추적\n",
    "#     for sub_batch in batch:  # collate_fn이 배치 크기만큼 나눠서 반환\n",
    "#         print(f\"Batch size: {len(sub_batch['image_names'])}\")  # 배치 내 이미지 개수 확인\n",
    "#         print(f\"Image Tensor Shape: {sub_batch['images'].shape}\")  # [배치 크기, 3, crop_size, crop_size]\n",
    "#         print(f\"Image Names: {sub_batch['image_names']}\")  # 이미지 이름 리스트\n",
    "#         print(f\"Top Left Positions Shape: {sub_batch['top_left_positions'].shape}\")  # [배치 크기, 2]\n",
    "\n",
    "#         # 마지막 크롭된 이미지 정보 확인\n",
    "#         for last_info in sub_batch['last_cropped_images_info']:\n",
    "#             print(f\"Last Cropped Image Top-Left: {last_info['top_left']}\")\n",
    "#             print(f\"Last Cropped Image Bottom-Right: {last_info['bottom_right']}\")\n",
    "#             print(f\"Last Cropped Image Size: {last_info['size']}\")  # 마지막 크롭된 이미지 크기 확인\n",
    "\n",
    "#             # 크롭된 이미지가 정확한 크기인지 확인 (경계 부분이 잘 처리되었는지 확인)\n",
    "#             if last_info['size'][0] <= crop_size and last_info['size'][1] <= crop_size:\n",
    "#                 print(\"Last cropped image size is correct.\")\n",
    "#             else:\n",
    "#                 print(\"Last cropped image size is incorrect.\")\n",
    "\n",
    "#         total_images += len(sub_batch['image_names'])  # 전체 이미지 개수 증가\n",
    "\n",
    "#     # 총 크롭 이미지 개수와 배치에서 나온 이미지 개수 비교\n",
    "#     print(f\"Total cropped images (from dataset): {sub_batch['total_crops']}\")\n",
    "#     print(f\"Total images processed from batches: {total_images}\")\n",
    "    \n",
    "#     # 총 크롭 이미지 개수가 배치에서 모두 나왔는지 검증\n",
    "#     if total_images == sub_batch['total_crops']:\n",
    "#         print(\"All cropped images from the dataset have been processed correctly.\")\n",
    "#     else:\n",
    "#         print(f\"Discrepancy: Processed {total_images} images, but expected {sub_batch['total_crops']} images.\")\n",
    "    \n",
    "#     break  # 첫 번째 이미지 데이터만 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceacc7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  torch.Tensor inputs should be normalized 0.0-1.0 but max value is 6.543742656707764. Dividing input by 255.\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# 이미지 목록을 가져오는 함수\n",
    "test_path = '../'\n",
    "# 사용 예시\n",
    "\n",
    "crop_size = 256  # 크롭할 이미지의 크기\n",
    "# test_path = '/workspace/dataset'\n",
    "img_list = get_imglist(test_path)\n",
    "color_stats_file = './train_color_stats.npz'\n",
    "batch_size = 1024\n",
    "# 모델 정의 \n",
    "model = YOLO(\"./best.pt\")  # YOLO OBB 모델 불러오기\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")  # GPU 또는 MPS 사용\n",
    "\n",
    "# 모델은 이미 내부적으로 GPU/MPS를 사용하므로 입력 이미지를 device로 보냄\n",
    "dataset = CroppedImageDataset(img_list, crop_size, color_stats_file)\n",
    "\n",
    "# DataLoader에서 batch_size를 16으로 설정\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=lambda x: collate_fn(x, batch_size))\n",
    "\n",
    "# YOLO 모델을 사용한 예측 함수\n",
    "def run_yolo_on_images(dataloader, model, device):\n",
    "    results = []  # 예측 결과를 저장할 리스트\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        for sub_batch in batch:  # 각 sub_batch에 대해 처리\n",
    "            images = sub_batch['images'].to(device)  # 이미지를 device로 전송\n",
    "            top_left_positions = sub_batch['top_left_positions'].to(device)  # 좌상단 좌표도 device로 전송\n",
    "            \n",
    "            # YOLO 모델 예측 수행\n",
    "            preds = model.predict(images,conf=0.1,save=True)  # Ultralytics YOLO 모델의 predict 함수 사용\n",
    "\n",
    "            obb = [ pred.obb.xywhr for pred in preds]\n",
    "            results.append({\n",
    "                'image_names': sub_batch['image_names'],\n",
    "                'obb':obb,\n",
    "                'top_left_positions': top_left_positions\n",
    "                \n",
    "            })\n",
    "            print(f\"Processed {len(sub_batch['image_names'])} images with predictions.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 모델을 사용한 예측 수행\n",
    "predictions = []\n",
    "predictions += run_yolo_on_images(dataloader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b920ec48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일 './submission.csv'이(가) 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "import math\n",
    "\n",
    "# 파일 저장할 CSV 경로\n",
    "csv_file = \"./submission.csv\"\n",
    "\n",
    "# 데이터 샘플 (image_name, cx, cy, width, height, angle 등)\n",
    "data = []\n",
    "\n",
    "# NMS 임계값 (IoU 임계값)\n",
    "nms_threshold = 0.7\n",
    "\n",
    "# 'predictions' 리스트에 있는 각 배치에서 데이터를 추출\n",
    "for i in range(len(predictions)):  # predictions 리스트에서 하나씩 꺼냄\n",
    "    image_name = predictions[i]['image_names']  # 각 배치의 이미지 이름 리스트\n",
    "    obb_list = predictions[i]['obb']  # 각 배치의 obb 리스트\n",
    "    top_left_pos_list = predictions[i]['top_left_positions']  # 각 배치의 top_left_positions 리스트\n",
    "\n",
    "    # 각 배치에서 이미지별로 순회\n",
    "    for j in range(len(obb_list)):\n",
    "        obb_tensor = obb_list[j]\n",
    "        top_left_pos = top_left_pos_list[j]\n",
    "\n",
    "        # obb_tensor가 비어있지 않은 경우에만 처리\n",
    "        if len(obb_tensor) > 0:\n",
    "            # NMS 처리를 위한 준비\n",
    "            boxes = []\n",
    "            scores = []  # NMS를 위해 점수가 필요 (여기서는 객체 너비를 임시 점수로 사용)\n",
    "            for k in range(len(obb_tensor)):\n",
    "                # cx = obb_tensor[k][0].item() + top_left_pos[0].item()\n",
    "                # cy = obb_tensor[k][1].item() + top_left_pos[1].item()\n",
    "                cx = obb_tensor[k][0].item()/4.0 + top_left_pos[0].item()\n",
    "                cy = obb_tensor[k][1].item()/4.0 + top_left_pos[1].item()\n",
    "                width = obb_tensor[k][2].item()/4.0\n",
    "                height = obb_tensor[k][3].item()/4.0\n",
    "                angle = obb_tensor[k][4].item()\n",
    "\n",
    "                # 사각형 좌표로 변환 (cx, cy, width, height -> x1, y1, x2, y2)\n",
    "                x1 = cx - width / 2\n",
    "                y1 = cy - height / 2\n",
    "                x2 = cx + width / 2\n",
    "                y2 = cy + height / 2\n",
    "\n",
    "                # 박스와 점수 추가\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                scores.append(width)  # width를 임시 점수로 사용\n",
    "\n",
    "            # NMS 수행\n",
    "            boxes_tensor = torch.tensor(boxes, dtype=torch.float32)\n",
    "            scores_tensor = torch.tensor(scores, dtype=torch.float32)\n",
    "            nms_indices = nms(boxes_tensor, scores_tensor, nms_threshold)\n",
    "\n",
    "            # NMS 후 남은 객체들에 대해 각도 변환 및 데이터 추가\n",
    "            # NMS 후 남은 객체들에 대해 각도 변환 및 데이터 추가\n",
    "            for idx in nms_indices:\n",
    "                cx = obb_tensor[idx][0].item()/4.0 + top_left_pos[0].item()\n",
    "                cy = obb_tensor[idx][1].item()/4.0 + top_left_pos[1].item()\n",
    "                width = obb_tensor[idx][2].item()/4.0\n",
    "                height = obb_tensor[idx][3].item()/4.0\n",
    "                # cx = round(obb_tensor[idx][0].item()/4.0 + top_left_pos[0].item(), 2)\n",
    "                # cy = round(obb_tensor[idx][1].item()/4.0 + top_left_pos[1].item(), 2)\n",
    "                # width = round(obb_tensor[idx][2].item()/4.0, 2)\n",
    "                # height = round(obb_tensor[idx][3].item()/4.0, 2)\n",
    "                angle = obb_tensor[idx][4].item()\n",
    "                \n",
    "                # 라디안을 도 단위로 변환\n",
    "                angle_deg = math.degrees(angle)\n",
    "                \n",
    "                # 각도를 0~360도 범위로 변환\n",
    "                if angle_deg < 0:\n",
    "                    angle_deg += 360\n",
    "                    \n",
    "                angle_deg = round(angle_deg, 2)\n",
    "\n",
    "                # 데이터 추가\n",
    "                data.append([image_name[j], cx, cy, width, height, angle_deg])\n",
    "# CSV 파일로 저장\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # CSV의 헤더 작성\n",
    "    writer.writerow(['image_name', 'cx', 'cy', 'width', 'height', 'angle'])\n",
    "    \n",
    "    # 각 행을 작성\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV 파일 '{csv_file}'이(가) 성공적으로 생성되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75251594",
   "metadata": {},
   "source": [
    "### 4. aifactory 라이브러리를 이용한 제출 수행\n",
    "#### ※ task별, 참가자별로 key가 다릅니다. 잘못 입력하지 않도록 유의바랍니다.\n",
    "- key는 플랫폼 우측 상단 아이콘 - [마이페이지] - [활동히스토리] 아래 [Competition] 란에서 대회 이름으로 확인하실 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff84f65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n ice\n"
     ]
    }
   ],
   "source": [
    "print('n ice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fad1f41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file : task.py\n",
      "python\n",
      "제출 완료\n",
      "time: 19.929635047912598\n"
     ]
    }
   ],
   "source": [
    "import aifactory.score as aif\n",
    "import time\n",
    "\n",
    "t = time.time()\n",
    "aif.submit(model_name=\"yolo\",\n",
    "           key=\"128fd22e-34e1-4e7a-b9c9-3423c2e859ce\")\n",
    "print(\"time:\", time.time() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9ef961-5696-45fb-b3d4-173083b29f70",
   "metadata": {},
   "source": [
    "### 5. 기타 참고사항\n",
    "- 추론 수행 시간:\n",
    "  - 일반적으로 기본 사이즈의 YOLO계열 모델 사용 시 test set 전체 추론에는 1시간 정도가 소요됩니다.\n",
    "- CUDA Out of Memory 문제:\n",
    "  - GPU OOM이 발생하는 경우 \n",
    "    - 각 image 사이 또는 batch 사이에 torch.cuda.empty_cache() 및 gc.collect()를 입력하여 VRAM의 낭비 공간을 정리하거나\n",
    "    - Batch size를 조절하는 방법 등을 활용해볼 수 있습니다.\n",
    "- Storage:\n",
    "  - 추론 환경에서는 참가자 분의 모델 및 기타 산출물이 임시 저장되는 공간으로 기본 32GB가 제공되므로 작업 시에 참고 부탁드립니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
