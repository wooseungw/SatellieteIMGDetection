{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q ultralytics\n",
    "!pip install -U -q aifactory\n",
    "!pip install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True' \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # 이미지 파일이 손상되었을 때 에러 발생 방지\n",
    "\n",
    "def get_imglist(dir=\"/workspace/dataset/\"):\n",
    "    imglist = [os.path.join(dir, f).replace(\"\\\\\", \"/\") for f in os.listdir(dir) if f.endswith('.png')]\n",
    "    return imglist\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_temp_dir(base_dir='./temp_cropped_patches'):\n",
    "    # 임시 폴더가 이미 존재하면 삭제하고 새로 생성\n",
    "    if os.path.exists(base_dir):\n",
    "        shutil.rmtree(base_dir)\n",
    "    os.makedirs(base_dir)\n",
    "    return base_dir\n",
    "\n",
    "def save_cropped_patches_single_image(image_path, crop_size, save_dir):\n",
    "    image_name = os.path.basename(image_path)\n",
    "    print(f\"Cropping image: {image_name}\")\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_width, image_height = image.size\n",
    "    \n",
    "    num_patches_x = (image_width + crop_size - 1) // crop_size\n",
    "    num_patches_y = (image_height + crop_size - 1) // crop_size\n",
    "    \n",
    "    for i in tqdm(range(num_patches_x)):\n",
    "        for j in range(num_patches_y):\n",
    "            top_left_x = i * crop_size\n",
    "            top_left_y = j * crop_size\n",
    "            bottom_right_x = min(top_left_x + crop_size, image_width)\n",
    "            bottom_right_y = min(top_left_y + crop_size, image_height)\n",
    "            \n",
    "            if bottom_right_x - top_left_x < crop_size:\n",
    "                top_left_x = max(image_width - crop_size, 0)\n",
    "                bottom_right_x = image_width\n",
    "            if bottom_right_y - top_left_y < crop_size:\n",
    "                top_left_y = max(image_height - crop_size, 0)\n",
    "                bottom_right_y = image_height\n",
    "            \n",
    "            cropped_image = image.crop((top_left_x, top_left_y, bottom_right_x, bottom_right_y))\n",
    "            \n",
    "            \n",
    "            \n",
    "            crop_filename = f\"{os.path.splitext(image_name)[0]}_{top_left_x}_{top_left_y}.png\"\n",
    "            crop_path = os.path.join(save_dir, crop_filename)\n",
    "            cropped_image.save(crop_path)\n",
    "    \n",
    "    del image\n",
    "    \n",
    "class CroppedPatchDataset(Dataset):\n",
    "    def __init__(self, crop_image_dir,resize_size):\n",
    "        self.crop_image_paths = crop_image_dir\n",
    "        self.transform = transforms.ToTensor()\n",
    "        self.resize_size = resize_size\n",
    "    def __len__(self):\n",
    "        return len(self.crop_image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        crop_image_path = self.crop_image_paths[idx]\n",
    "        image_name = os.path.basename(crop_image_path)\n",
    "        \n",
    "        cropped_image = Image.open(crop_image_path).convert('RGB')\n",
    "        \n",
    "        cropped_image = cropped_image.resize((self.resize_size,self.resize_size), resample=Image.Resampling.LANCZOS)\n",
    "        # BGR로 변환\n",
    "        cropped_image_np = np.array(cropped_image)\n",
    "        cropped_image_bgr = cropped_image_np[:, :, ::-1]\n",
    "        cropped_image_pil = Image.fromarray(cropped_image_bgr, 'RGB')\n",
    "        \n",
    "        cropped_image_tensor = self.transform(cropped_image_pil)\n",
    "        \n",
    "        \n",
    "        name_parts = image_name.split('_')\n",
    "        top_left_x = int(name_parts[-2])\n",
    "        top_left_y = int(name_parts[-1].split('.')[0])\n",
    "        position = torch.tensor([top_left_x, top_left_y])\n",
    "        \n",
    "        original_image_name = '_'.join(name_parts[:-2]) + '.png'\n",
    "        \n",
    "        return {\n",
    "            'image_name': original_image_name,\n",
    "            'image': cropped_image_tensor,\n",
    "            'top_left_position': position\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(image_names, images, positions, model,scale_factor, result):\n",
    "    scale_factor =scale_factor # 예측 스케일과 패치 스케일의 비율: 256 / 1024\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    preds = model.predict(images, conf=0.15, save=False,device= device)  # 예측 결과: [batch_size]\n",
    "\n",
    "    for img_name, pred, pos in zip(image_names, preds, positions):\n",
    "        if img_name not in result:\n",
    "            result[img_name] = []\n",
    "\n",
    "        top_left_x, top_left_y = pos[0].item(), pos[1].item()\n",
    "\n",
    "        # 좌표 변환 및 conf 값 포함하여 저장\n",
    "        for i in range(len(pred)):\n",
    "            bbox = pred.obb.xywhr[i]  # [x, y, w, h, r]\n",
    "            confidence = pred.obb.conf[i]  # confidence 값\n",
    "            \n",
    "            # bbox가 비어 있는 경우 해당 항목을 넘김\n",
    "            if len(bbox) == 0:\n",
    "            # bbox가 비어있음\n",
    "                continue\n",
    "\n",
    "            # 예측된 좌표를 원본 이미지 좌표로 변환\n",
    "            x = bbox[0].item() * scale_factor + top_left_x\n",
    "            y = bbox[1].item() * scale_factor + top_left_y\n",
    "            w = bbox[2].item() * scale_factor\n",
    "            h = bbox[3].item() * scale_factor\n",
    "            r = bbox[4].item()  # 각도 값은 변환 불필요\n",
    "\n",
    "            # 변환된 좌표와 confidence를 결과 리스트에 추가\n",
    "            result[img_name].append({\n",
    "                'xywhr': [x, y, w, h, r],\n",
    "                'conf': confidence.item()\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/2\n",
      "Cropping image: task_smaple.png\n",
      "Cropping image: task_smaple.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/PIL/Image.py:3368: DecompressionBombWarning: Image size (120560400 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.ops import nms_rotated\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 경로 설정\n",
    "directory_path = '/workspace/dataset/'\n",
    "directory_path = './'\n",
    "base_dir = './temp_cropped_patches'\n",
    "img_list = get_imglist(directory_path)\n",
    "\n",
    "# 모델 설정\n",
    "model_name = \"./yolo11n-obb.pt\"\n",
    "crop_size = 512\n",
    "resize_size = 1024\n",
    "batch_size = 32\n",
    "model = YOLO(model_name)\n",
    "\n",
    "result = {}  # 최종 결과를 저장할 딕셔너리\n",
    "\n",
    "length = len(img_list)\n",
    "divide_num = 2  # 원하는 분할 수로 설정\n",
    "img_list_chunks = [img_list[i:i + length // divide_num] for i in range(0, length, length // divide_num)]\n",
    "\n",
    "for chunk_idx, img_chunk in enumerate(img_list_chunks):\n",
    "    # 임시 폴더 생성\n",
    "    temp_dir = create_temp_dir(base_dir=base_dir)\n",
    "    print(f\"Processing chunk {chunk_idx + 1}/{len(img_list_chunks)}\")\n",
    "\n",
    "    # 현재 청크의 이미지별 결과 리스트 초기화\n",
    "    for image_path in img_chunk:\n",
    "        image_name = os.path.basename(image_path)\n",
    "        result[image_name] = []\n",
    "\n",
    "    # 모든 이미지를 크롭하여 임시 폴더에 저장\n",
    "    for image_path in img_chunk:\n",
    "        image_name = os.path.basename(image_path)\n",
    "        print(f\"Cropping image: {image_name}\")\n",
    "        # 패치 저장 시 일관된 이름 지정\n",
    "        save_cropped_patches_single_image(image_path, crop_size, temp_dir)\n",
    "\n",
    "    # 임시 폴더 내의 모든 패치 이미지 리스트 가져오기\n",
    "    temp_list = get_imglist(temp_dir)\n",
    "\n",
    "    # 데이터셋 및 DataLoader 설정\n",
    "    dataset = CroppedPatchDataset(temp_list, resize_size=resize_size)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=0)  # 필요에 따라 num_workers 조정\n",
    "\n",
    "    for batch in dataloader:\n",
    "        images = batch['image']\n",
    "        positions = batch['top_left_position']\n",
    "        patch_image_names = batch['image_name']\n",
    "\n",
    "        # 패치 이미지 이름에서 원본 이미지 이름과 위치 추출\n",
    "        original_image_names = []\n",
    "        for patch_name in patch_image_names:\n",
    "            # 패치 이미지 이름이 'original_image_x_y.png' 형식이라고 가정\n",
    "            base_name = os.path.splitext(patch_name)[0]\n",
    "            parts = base_name.split('_')\n",
    "            original_image_name = '_'.join(parts[:-2]) + '.png'  # 확장자는 필요에 따라 조정\n",
    "            original_image_names.append(original_image_name)\n",
    "\n",
    "        # 모델 실행 및 결과 저장\n",
    "        run_model(original_image_names, images, positions, model, crop_size / resize_size, result)\n",
    "\n",
    "    # 현재 청크의 모든 이미지에 대해 NMS 적용\n",
    "    for image_path in img_chunk:\n",
    "        image_name = os.path.basename(image_path)\n",
    "        per_image_result = result[image_name]\n",
    "        if per_image_result:\n",
    "            # boxes와 scores 추출\n",
    "            boxes = torch.tensor([pred['xywhr'] for pred in per_image_result])\n",
    "            scores = torch.tensor([pred['conf'] for pred in per_image_result])\n",
    "\n",
    "            # NMS 적용\n",
    "            keep_indices = nms_rotated(boxes, scores, threshold=0.45)\n",
    "\n",
    "            # NMS 결과를 최종적으로 업데이트\n",
    "            result[image_name] = [per_image_result[i] for i in keep_indices]\n",
    "\n",
    "    # 쿠다 캐시 제거 및 불필요한 메모리 제거\n",
    "    torch.cuda.empty_cache()\n",
    "    del dataset\n",
    "    del dataloader\n",
    "    # 임시 폴더 삭제\n",
    "    shutil.rmtree(temp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: task_smaple.png\n",
      "Cropping image: task_smaple.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ship\\Lib\\site-packages\\PIL\\Image.py:3186: DecompressionBombWarning: Image size (120560400 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "100%|██████████| 22/22 [00:34<00:00,  1.58s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]c:\\ProgramData\\anaconda3\\envs\\ship\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 23.8ms\n",
      "1: 1024x1024 (no detections), 23.8ms\n",
      "2: 1024x1024 23.8ms\n",
      "3: 1024x1024 23.8ms\n",
      "4: 1024x1024 23.8ms\n",
      "5: 1024x1024 (no detections), 23.8ms\n",
      "6: 1024x1024 (no detections), 23.8ms\n",
      "7: 1024x1024 (no detections), 23.8ms\n",
      "8: 1024x1024 (no detections), 23.8ms\n",
      "9: 1024x1024 (no detections), 23.8ms\n",
      "10: 1024x1024 (no detections), 23.8ms\n",
      "11: 1024x1024 (no detections), 23.8ms\n",
      "12: 1024x1024 (no detections), 23.8ms\n",
      "13: 1024x1024 (no detections), 23.8ms\n",
      "14: 1024x1024 23.8ms\n",
      "15: 1024x1024 (no detections), 23.8ms\n",
      "16: 1024x1024 (no detections), 23.8ms\n",
      "17: 1024x1024 (no detections), 23.8ms\n",
      "18: 1024x1024 (no detections), 23.8ms\n",
      "19: 1024x1024 23.8ms\n",
      "20: 1024x1024 23.8ms\n",
      "21: 1024x1024 23.8ms\n",
      "22: 1024x1024 23.8ms\n",
      "23: 1024x1024 23.8ms\n",
      "Speed: 1.7ms preprocess, 23.8ms inference, 18.5ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/21 [00:02<00:54,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 21.0ms\n",
      "1: 1024x1024 21.0ms\n",
      "2: 1024x1024 21.0ms\n",
      "3: 1024x1024 21.0ms\n",
      "4: 1024x1024 (no detections), 21.0ms\n",
      "5: 1024x1024 (no detections), 21.0ms\n",
      "6: 1024x1024 (no detections), 21.0ms\n",
      "7: 1024x1024 21.0ms\n",
      "8: 1024x1024 (no detections), 21.0ms\n",
      "9: 1024x1024 21.0ms\n",
      "10: 1024x1024 (no detections), 21.0ms\n",
      "11: 1024x1024 (no detections), 21.0ms\n",
      "12: 1024x1024 (no detections), 21.0ms\n",
      "13: 1024x1024 (no detections), 21.0ms\n",
      "14: 1024x1024 (no detections), 21.0ms\n",
      "15: 1024x1024 (no detections), 21.0ms\n",
      "16: 1024x1024 (no detections), 21.0ms\n",
      "17: 1024x1024 21.0ms\n",
      "18: 1024x1024 21.0ms\n",
      "19: 1024x1024 (no detections), 21.0ms\n",
      "20: 1024x1024 (no detections), 21.0ms\n",
      "21: 1024x1024 (no detections), 21.0ms\n",
      "22: 1024x1024 (no detections), 21.0ms\n",
      "23: 1024x1024 (no detections), 21.0ms\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 12.5ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2/21 [00:04<00:42,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 21.1ms\n",
      "1: 1024x1024 (no detections), 21.1ms\n",
      "2: 1024x1024 (no detections), 21.1ms\n",
      "3: 1024x1024 (no detections), 21.1ms\n",
      "4: 1024x1024 (no detections), 21.1ms\n",
      "5: 1024x1024 (no detections), 21.1ms\n",
      "6: 1024x1024 (no detections), 21.1ms\n",
      "7: 1024x1024 (no detections), 21.1ms\n",
      "8: 1024x1024 (no detections), 21.1ms\n",
      "9: 1024x1024 (no detections), 21.1ms\n",
      "10: 1024x1024 (no detections), 21.1ms\n",
      "11: 1024x1024 (no detections), 21.1ms\n",
      "12: 1024x1024 (no detections), 21.1ms\n",
      "13: 1024x1024 (no detections), 21.1ms\n",
      "14: 1024x1024 21.1ms\n",
      "15: 1024x1024 21.1ms\n",
      "16: 1024x1024 21.1ms\n",
      "17: 1024x1024 21.1ms\n",
      "18: 1024x1024 21.1ms\n",
      "19: 1024x1024 21.1ms\n",
      "20: 1024x1024 (no detections), 21.1ms\n",
      "21: 1024x1024 21.1ms\n",
      "22: 1024x1024 21.1ms\n",
      "23: 1024x1024 (no detections), 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 13.5ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:06<00:37,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 21.1ms\n",
      "1: 1024x1024 (no detections), 21.1ms\n",
      "2: 1024x1024 (no detections), 21.1ms\n",
      "3: 1024x1024 21.1ms\n",
      "4: 1024x1024 (no detections), 21.1ms\n",
      "5: 1024x1024 21.1ms\n",
      "6: 1024x1024 (no detections), 21.1ms\n",
      "7: 1024x1024 (no detections), 21.1ms\n",
      "8: 1024x1024 (no detections), 21.1ms\n",
      "9: 1024x1024 (no detections), 21.1ms\n",
      "10: 1024x1024 (no detections), 21.1ms\n",
      "11: 1024x1024 (no detections), 21.1ms\n",
      "12: 1024x1024 21.1ms\n",
      "13: 1024x1024 (no detections), 21.1ms\n",
      "14: 1024x1024 21.1ms\n",
      "15: 1024x1024 (no detections), 21.1ms\n",
      "16: 1024x1024 (no detections), 21.1ms\n",
      "17: 1024x1024 (no detections), 21.1ms\n",
      "18: 1024x1024 21.1ms\n",
      "19: 1024x1024 (no detections), 21.1ms\n",
      "20: 1024x1024 (no detections), 21.1ms\n",
      "21: 1024x1024 (no detections), 21.1ms\n",
      "22: 1024x1024 (no detections), 21.1ms\n",
      "23: 1024x1024 (no detections), 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 13.2ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 4/21 [00:08<00:33,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 20.9ms\n",
      "1: 1024x1024 (no detections), 20.9ms\n",
      "2: 1024x1024 (no detections), 20.9ms\n",
      "3: 1024x1024 (no detections), 20.9ms\n",
      "4: 1024x1024 (no detections), 20.9ms\n",
      "5: 1024x1024 20.9ms\n",
      "6: 1024x1024 (no detections), 20.9ms\n",
      "7: 1024x1024 (no detections), 20.9ms\n",
      "8: 1024x1024 (no detections), 20.9ms\n",
      "9: 1024x1024 (no detections), 20.9ms\n",
      "10: 1024x1024 (no detections), 20.9ms\n",
      "11: 1024x1024 (no detections), 20.9ms\n",
      "12: 1024x1024 20.9ms\n",
      "13: 1024x1024 (no detections), 20.9ms\n",
      "14: 1024x1024 (no detections), 20.9ms\n",
      "15: 1024x1024 (no detections), 20.9ms\n",
      "16: 1024x1024 (no detections), 20.9ms\n",
      "17: 1024x1024 (no detections), 20.9ms\n",
      "18: 1024x1024 (no detections), 20.9ms\n",
      "19: 1024x1024 (no detections), 20.9ms\n",
      "20: 1024x1024 20.9ms\n",
      "21: 1024x1024 (no detections), 20.9ms\n",
      "22: 1024x1024 (no detections), 20.9ms\n",
      "23: 1024x1024 (no detections), 20.9ms\n",
      "Speed: 2.2ms preprocess, 20.9ms inference, 12.9ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:10<00:31,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 21.1ms\n",
      "1: 1024x1024 (no detections), 21.1ms\n",
      "2: 1024x1024 (no detections), 21.1ms\n",
      "3: 1024x1024 (no detections), 21.1ms\n",
      "4: 1024x1024 21.1ms\n",
      "5: 1024x1024 21.1ms\n",
      "6: 1024x1024 (no detections), 21.1ms\n",
      "7: 1024x1024 (no detections), 21.1ms\n",
      "8: 1024x1024 21.1ms\n",
      "9: 1024x1024 (no detections), 21.1ms\n",
      "10: 1024x1024 (no detections), 21.1ms\n",
      "11: 1024x1024 (no detections), 21.1ms\n",
      "12: 1024x1024 21.1ms\n",
      "13: 1024x1024 (no detections), 21.1ms\n",
      "14: 1024x1024 (no detections), 21.1ms\n",
      "15: 1024x1024 (no detections), 21.1ms\n",
      "16: 1024x1024 (no detections), 21.1ms\n",
      "17: 1024x1024 (no detections), 21.1ms\n",
      "18: 1024x1024 (no detections), 21.1ms\n",
      "19: 1024x1024 (no detections), 21.1ms\n",
      "20: 1024x1024 (no detections), 21.1ms\n",
      "21: 1024x1024 21.1ms\n",
      "22: 1024x1024 (no detections), 21.1ms\n",
      "23: 1024x1024 (no detections), 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 12.6ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 6/21 [00:12<00:28,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 20.9ms\n",
      "1: 1024x1024 20.9ms\n",
      "2: 1024x1024 20.9ms\n",
      "3: 1024x1024 20.9ms\n",
      "4: 1024x1024 20.9ms\n",
      "5: 1024x1024 20.9ms\n",
      "6: 1024x1024 20.9ms\n",
      "7: 1024x1024 (no detections), 20.9ms\n",
      "8: 1024x1024 (no detections), 20.9ms\n",
      "9: 1024x1024 (no detections), 20.9ms\n",
      "10: 1024x1024 (no detections), 20.9ms\n",
      "11: 1024x1024 (no detections), 20.9ms\n",
      "12: 1024x1024 (no detections), 20.9ms\n",
      "13: 1024x1024 (no detections), 20.9ms\n",
      "14: 1024x1024 (no detections), 20.9ms\n",
      "15: 1024x1024 (no detections), 20.9ms\n",
      "16: 1024x1024 (no detections), 20.9ms\n",
      "17: 1024x1024 (no detections), 20.9ms\n",
      "18: 1024x1024 (no detections), 20.9ms\n",
      "19: 1024x1024 (no detections), 20.9ms\n",
      "20: 1024x1024 (no detections), 20.9ms\n",
      "21: 1024x1024 (no detections), 20.9ms\n",
      "22: 1024x1024 20.9ms\n",
      "23: 1024x1024 20.9ms\n",
      "Speed: 1.7ms preprocess, 20.9ms inference, 13.7ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 7/21 [00:14<00:26,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 21.1ms\n",
      "1: 1024x1024 (no detections), 21.1ms\n",
      "2: 1024x1024 21.1ms\n",
      "3: 1024x1024 (no detections), 21.1ms\n",
      "4: 1024x1024 (no detections), 21.1ms\n",
      "5: 1024x1024 (no detections), 21.1ms\n",
      "6: 1024x1024 (no detections), 21.1ms\n",
      "7: 1024x1024 (no detections), 21.1ms\n",
      "8: 1024x1024 (no detections), 21.1ms\n",
      "9: 1024x1024 (no detections), 21.1ms\n",
      "10: 1024x1024 (no detections), 21.1ms\n",
      "11: 1024x1024 (no detections), 21.1ms\n",
      "12: 1024x1024 21.1ms\n",
      "13: 1024x1024 21.1ms\n",
      "14: 1024x1024 (no detections), 21.1ms\n",
      "15: 1024x1024 (no detections), 21.1ms\n",
      "16: 1024x1024 21.1ms\n",
      "17: 1024x1024 (no detections), 21.1ms\n",
      "18: 1024x1024 (no detections), 21.1ms\n",
      "19: 1024x1024 (no detections), 21.1ms\n",
      "20: 1024x1024 (no detections), 21.1ms\n",
      "21: 1024x1024 (no detections), 21.1ms\n",
      "22: 1024x1024 21.1ms\n",
      "23: 1024x1024 (no detections), 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 12.9ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 8/21 [00:15<00:24,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 21.0ms\n",
      "1: 1024x1024 21.0ms\n",
      "2: 1024x1024 (no detections), 21.0ms\n",
      "3: 1024x1024 (no detections), 21.0ms\n",
      "4: 1024x1024 (no detections), 21.0ms\n",
      "5: 1024x1024 (no detections), 21.0ms\n",
      "6: 1024x1024 (no detections), 21.0ms\n",
      "7: 1024x1024 21.0ms\n",
      "8: 1024x1024 (no detections), 21.0ms\n",
      "9: 1024x1024 (no detections), 21.0ms\n",
      "10: 1024x1024 21.0ms\n",
      "11: 1024x1024 21.0ms\n",
      "12: 1024x1024 21.0ms\n",
      "13: 1024x1024 21.0ms\n",
      "14: 1024x1024 (no detections), 21.0ms\n",
      "15: 1024x1024 (no detections), 21.0ms\n",
      "16: 1024x1024 (no detections), 21.0ms\n",
      "17: 1024x1024 (no detections), 21.0ms\n",
      "18: 1024x1024 (no detections), 21.0ms\n",
      "19: 1024x1024 (no detections), 21.0ms\n",
      "20: 1024x1024 21.0ms\n",
      "21: 1024x1024 21.0ms\n",
      "22: 1024x1024 21.0ms\n",
      "23: 1024x1024 21.0ms\n",
      "Speed: 1.9ms preprocess, 21.0ms inference, 14.1ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 9/21 [00:17<00:23,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 21.5ms\n",
      "1: 1024x1024 (no detections), 21.5ms\n",
      "2: 1024x1024 (no detections), 21.5ms\n",
      "3: 1024x1024 (no detections), 21.5ms\n",
      "4: 1024x1024 21.5ms\n",
      "5: 1024x1024 21.5ms\n",
      "6: 1024x1024 (no detections), 21.5ms\n",
      "7: 1024x1024 (no detections), 21.5ms\n",
      "8: 1024x1024 21.5ms\n",
      "9: 1024x1024 21.5ms\n",
      "10: 1024x1024 21.5ms\n",
      "11: 1024x1024 (no detections), 21.5ms\n",
      "12: 1024x1024 21.5ms\n",
      "13: 1024x1024 (no detections), 21.5ms\n",
      "14: 1024x1024 (no detections), 21.5ms\n",
      "15: 1024x1024 21.5ms\n",
      "16: 1024x1024 (no detections), 21.5ms\n",
      "17: 1024x1024 (no detections), 21.5ms\n",
      "18: 1024x1024 21.5ms\n",
      "19: 1024x1024 21.5ms\n",
      "20: 1024x1024 21.5ms\n",
      "21: 1024x1024 21.5ms\n",
      "22: 1024x1024 (no detections), 21.5ms\n",
      "23: 1024x1024 (no detections), 21.5ms\n",
      "Speed: 2.6ms preprocess, 21.5ms inference, 13.9ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 10/21 [00:19<00:21,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 21.6ms\n",
      "1: 1024x1024 (no detections), 21.6ms\n",
      "2: 1024x1024 (no detections), 21.6ms\n",
      "3: 1024x1024 21.6ms\n",
      "4: 1024x1024 21.6ms\n",
      "5: 1024x1024 21.6ms\n",
      "6: 1024x1024 21.6ms\n",
      "7: 1024x1024 21.6ms\n",
      "8: 1024x1024 21.6ms\n",
      "9: 1024x1024 21.6ms\n",
      "10: 1024x1024 21.6ms\n",
      "11: 1024x1024 21.6ms\n",
      "12: 1024x1024 21.6ms\n",
      "13: 1024x1024 21.6ms\n",
      "14: 1024x1024 21.6ms\n",
      "15: 1024x1024 (no detections), 21.6ms\n",
      "16: 1024x1024 (no detections), 21.6ms\n",
      "17: 1024x1024 (no detections), 21.6ms\n",
      "18: 1024x1024 21.6ms\n",
      "19: 1024x1024 21.6ms\n",
      "20: 1024x1024 (no detections), 21.6ms\n",
      "21: 1024x1024 (no detections), 21.6ms\n",
      "22: 1024x1024 (no detections), 21.6ms\n",
      "23: 1024x1024 (no detections), 21.6ms\n",
      "Speed: 3.0ms preprocess, 21.6ms inference, 14.9ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 11/21 [00:21<00:19,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 21.3ms\n",
      "1: 1024x1024 (no detections), 21.3ms\n",
      "2: 1024x1024 21.3ms\n",
      "3: 1024x1024 (no detections), 21.3ms\n",
      "4: 1024x1024 (no detections), 21.3ms\n",
      "5: 1024x1024 (no detections), 21.3ms\n",
      "6: 1024x1024 (no detections), 21.3ms\n",
      "7: 1024x1024 (no detections), 21.3ms\n",
      "8: 1024x1024 (no detections), 21.3ms\n",
      "9: 1024x1024 (no detections), 21.3ms\n",
      "10: 1024x1024 (no detections), 21.3ms\n",
      "11: 1024x1024 (no detections), 21.3ms\n",
      "12: 1024x1024 (no detections), 21.3ms\n",
      "13: 1024x1024 (no detections), 21.3ms\n",
      "14: 1024x1024 21.3ms\n",
      "15: 1024x1024 (no detections), 21.3ms\n",
      "16: 1024x1024 (no detections), 21.3ms\n",
      "17: 1024x1024 (no detections), 21.3ms\n",
      "18: 1024x1024 21.3ms\n",
      "19: 1024x1024 21.3ms\n",
      "20: 1024x1024 21.3ms\n",
      "21: 1024x1024 21.3ms\n",
      "22: 1024x1024 (no detections), 21.3ms\n",
      "23: 1024x1024 21.3ms\n",
      "Speed: 1.5ms preprocess, 21.3ms inference, 13.0ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 12/21 [00:23<00:17,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 21.3ms\n",
      "1: 1024x1024 (no detections), 21.3ms\n",
      "2: 1024x1024 (no detections), 21.3ms\n",
      "3: 1024x1024 21.3ms\n",
      "4: 1024x1024 (no detections), 21.3ms\n",
      "5: 1024x1024 21.3ms\n",
      "6: 1024x1024 (no detections), 21.3ms\n",
      "7: 1024x1024 21.3ms\n",
      "8: 1024x1024 (no detections), 21.3ms\n",
      "9: 1024x1024 21.3ms\n",
      "10: 1024x1024 (no detections), 21.3ms\n",
      "11: 1024x1024 (no detections), 21.3ms\n",
      "12: 1024x1024 21.3ms\n",
      "13: 1024x1024 (no detections), 21.3ms\n",
      "14: 1024x1024 21.3ms\n",
      "15: 1024x1024 (no detections), 21.3ms\n",
      "16: 1024x1024 21.3ms\n",
      "17: 1024x1024 (no detections), 21.3ms\n",
      "18: 1024x1024 (no detections), 21.3ms\n",
      "19: 1024x1024 21.3ms\n",
      "20: 1024x1024 21.3ms\n",
      "21: 1024x1024 (no detections), 21.3ms\n",
      "22: 1024x1024 (no detections), 21.3ms\n",
      "23: 1024x1024 (no detections), 21.3ms\n",
      "Speed: 1.6ms preprocess, 21.3ms inference, 13.3ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 13/21 [00:25<00:15,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 20.9ms\n",
      "1: 1024x1024 (no detections), 20.9ms\n",
      "2: 1024x1024 20.9ms\n",
      "3: 1024x1024 20.9ms\n",
      "4: 1024x1024 (no detections), 20.9ms\n",
      "5: 1024x1024 20.9ms\n",
      "6: 1024x1024 20.9ms\n",
      "7: 1024x1024 20.9ms\n",
      "8: 1024x1024 (no detections), 20.9ms\n",
      "9: 1024x1024 20.9ms\n",
      "10: 1024x1024 (no detections), 20.9ms\n",
      "11: 1024x1024 (no detections), 20.9ms\n",
      "12: 1024x1024 (no detections), 20.9ms\n",
      "13: 1024x1024 20.9ms\n",
      "14: 1024x1024 (no detections), 20.9ms\n",
      "15: 1024x1024 (no detections), 20.9ms\n",
      "16: 1024x1024 20.9ms\n",
      "17: 1024x1024 (no detections), 20.9ms\n",
      "18: 1024x1024 (no detections), 20.9ms\n",
      "19: 1024x1024 (no detections), 20.9ms\n",
      "20: 1024x1024 (no detections), 20.9ms\n",
      "21: 1024x1024 (no detections), 20.9ms\n",
      "22: 1024x1024 (no detections), 20.9ms\n",
      "23: 1024x1024 20.9ms\n",
      "Speed: 1.4ms preprocess, 20.9ms inference, 13.1ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 14/21 [00:27<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 20.8ms\n",
      "1: 1024x1024 20.8ms\n",
      "2: 1024x1024 (no detections), 20.8ms\n",
      "3: 1024x1024 (no detections), 20.8ms\n",
      "4: 1024x1024 (no detections), 20.8ms\n",
      "5: 1024x1024 (no detections), 20.8ms\n",
      "6: 1024x1024 (no detections), 20.8ms\n",
      "7: 1024x1024 (no detections), 20.8ms\n",
      "8: 1024x1024 (no detections), 20.8ms\n",
      "9: 1024x1024 20.8ms\n",
      "10: 1024x1024 (no detections), 20.8ms\n",
      "11: 1024x1024 (no detections), 20.8ms\n",
      "12: 1024x1024 20.8ms\n",
      "13: 1024x1024 (no detections), 20.8ms\n",
      "14: 1024x1024 (no detections), 20.8ms\n",
      "15: 1024x1024 (no detections), 20.8ms\n",
      "16: 1024x1024 (no detections), 20.8ms\n",
      "17: 1024x1024 20.8ms\n",
      "18: 1024x1024 (no detections), 20.8ms\n",
      "19: 1024x1024 (no detections), 20.8ms\n",
      "20: 1024x1024 20.8ms\n",
      "21: 1024x1024 20.8ms\n",
      "22: 1024x1024 20.8ms\n",
      "23: 1024x1024 (no detections), 20.8ms\n",
      "Speed: 1.6ms preprocess, 20.8ms inference, 13.9ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 15/21 [00:29<00:11,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 20.8ms\n",
      "1: 1024x1024 20.8ms\n",
      "2: 1024x1024 (no detections), 20.8ms\n",
      "3: 1024x1024 (no detections), 20.8ms\n",
      "4: 1024x1024 20.8ms\n",
      "5: 1024x1024 20.8ms\n",
      "6: 1024x1024 20.8ms\n",
      "7: 1024x1024 (no detections), 20.8ms\n",
      "8: 1024x1024 (no detections), 20.8ms\n",
      "9: 1024x1024 (no detections), 20.8ms\n",
      "10: 1024x1024 (no detections), 20.8ms\n",
      "11: 1024x1024 (no detections), 20.8ms\n",
      "12: 1024x1024 (no detections), 20.8ms\n",
      "13: 1024x1024 (no detections), 20.8ms\n",
      "14: 1024x1024 (no detections), 20.8ms\n",
      "15: 1024x1024 20.8ms\n",
      "16: 1024x1024 (no detections), 20.8ms\n",
      "17: 1024x1024 (no detections), 20.8ms\n",
      "18: 1024x1024 (no detections), 20.8ms\n",
      "19: 1024x1024 (no detections), 20.8ms\n",
      "20: 1024x1024 20.8ms\n",
      "21: 1024x1024 (no detections), 20.8ms\n",
      "22: 1024x1024 (no detections), 20.8ms\n",
      "23: 1024x1024 (no detections), 20.8ms\n",
      "Speed: 1.4ms preprocess, 20.8ms inference, 12.6ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 16/21 [00:31<00:09,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 20.7ms\n",
      "1: 1024x1024 (no detections), 20.7ms\n",
      "2: 1024x1024 20.7ms\n",
      "3: 1024x1024 (no detections), 20.7ms\n",
      "4: 1024x1024 (no detections), 20.7ms\n",
      "5: 1024x1024 (no detections), 20.7ms\n",
      "6: 1024x1024 (no detections), 20.7ms\n",
      "7: 1024x1024 (no detections), 20.7ms\n",
      "8: 1024x1024 (no detections), 20.7ms\n",
      "9: 1024x1024 (no detections), 20.7ms\n",
      "10: 1024x1024 (no detections), 20.7ms\n",
      "11: 1024x1024 (no detections), 20.7ms\n",
      "12: 1024x1024 (no detections), 20.7ms\n",
      "13: 1024x1024 (no detections), 20.7ms\n",
      "14: 1024x1024 (no detections), 20.7ms\n",
      "15: 1024x1024 (no detections), 20.7ms\n",
      "16: 1024x1024 (no detections), 20.7ms\n",
      "17: 1024x1024 20.7ms\n",
      "18: 1024x1024 (no detections), 20.7ms\n",
      "19: 1024x1024 20.7ms\n",
      "20: 1024x1024 20.7ms\n",
      "21: 1024x1024 (no detections), 20.7ms\n",
      "22: 1024x1024 (no detections), 20.7ms\n",
      "23: 1024x1024 (no detections), 20.7ms\n",
      "Speed: 1.5ms preprocess, 20.7ms inference, 13.1ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 17/21 [00:33<00:07,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 20.8ms\n",
      "1: 1024x1024 (no detections), 20.8ms\n",
      "2: 1024x1024 (no detections), 20.8ms\n",
      "3: 1024x1024 (no detections), 20.8ms\n",
      "4: 1024x1024 (no detections), 20.8ms\n",
      "5: 1024x1024 (no detections), 20.8ms\n",
      "6: 1024x1024 (no detections), 20.8ms\n",
      "7: 1024x1024 (no detections), 20.8ms\n",
      "8: 1024x1024 (no detections), 20.8ms\n",
      "9: 1024x1024 (no detections), 20.8ms\n",
      "10: 1024x1024 (no detections), 20.8ms\n",
      "11: 1024x1024 (no detections), 20.8ms\n",
      "12: 1024x1024 (no detections), 20.8ms\n",
      "13: 1024x1024 (no detections), 20.8ms\n",
      "14: 1024x1024 20.8ms\n",
      "15: 1024x1024 20.8ms\n",
      "16: 1024x1024 (no detections), 20.8ms\n",
      "17: 1024x1024 20.8ms\n",
      "18: 1024x1024 (no detections), 20.8ms\n",
      "19: 1024x1024 20.8ms\n",
      "20: 1024x1024 20.8ms\n",
      "21: 1024x1024 20.8ms\n",
      "22: 1024x1024 (no detections), 20.8ms\n",
      "23: 1024x1024 (no detections), 20.8ms\n",
      "Speed: 1.5ms preprocess, 20.8ms inference, 13.3ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 18/21 [00:35<00:05,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 20.8ms\n",
      "1: 1024x1024 (no detections), 20.8ms\n",
      "2: 1024x1024 (no detections), 20.8ms\n",
      "3: 1024x1024 (no detections), 20.8ms\n",
      "4: 1024x1024 (no detections), 20.8ms\n",
      "5: 1024x1024 (no detections), 20.8ms\n",
      "6: 1024x1024 (no detections), 20.8ms\n",
      "7: 1024x1024 (no detections), 20.8ms\n",
      "8: 1024x1024 20.8ms\n",
      "9: 1024x1024 (no detections), 20.8ms\n",
      "10: 1024x1024 (no detections), 20.8ms\n",
      "11: 1024x1024 (no detections), 20.8ms\n",
      "12: 1024x1024 20.8ms\n",
      "13: 1024x1024 20.8ms\n",
      "14: 1024x1024 (no detections), 20.8ms\n",
      "15: 1024x1024 20.8ms\n",
      "16: 1024x1024 20.8ms\n",
      "17: 1024x1024 (no detections), 20.8ms\n",
      "18: 1024x1024 (no detections), 20.8ms\n",
      "19: 1024x1024 (no detections), 20.8ms\n",
      "20: 1024x1024 (no detections), 20.8ms\n",
      "21: 1024x1024 (no detections), 20.8ms\n",
      "22: 1024x1024 (no detections), 20.8ms\n",
      "23: 1024x1024 (no detections), 20.8ms\n",
      "Speed: 2.0ms preprocess, 20.8ms inference, 13.7ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 19/21 [00:37<00:03,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 20.8ms\n",
      "1: 1024x1024 (no detections), 20.8ms\n",
      "2: 1024x1024 (no detections), 20.8ms\n",
      "3: 1024x1024 (no detections), 20.8ms\n",
      "4: 1024x1024 (no detections), 20.8ms\n",
      "5: 1024x1024 (no detections), 20.8ms\n",
      "6: 1024x1024 20.8ms\n",
      "7: 1024x1024 20.8ms\n",
      "8: 1024x1024 (no detections), 20.8ms\n",
      "9: 1024x1024 (no detections), 20.8ms\n",
      "10: 1024x1024 (no detections), 20.8ms\n",
      "11: 1024x1024 20.8ms\n",
      "12: 1024x1024 (no detections), 20.8ms\n",
      "13: 1024x1024 (no detections), 20.8ms\n",
      "14: 1024x1024 (no detections), 20.8ms\n",
      "15: 1024x1024 (no detections), 20.8ms\n",
      "16: 1024x1024 (no detections), 20.8ms\n",
      "17: 1024x1024 20.8ms\n",
      "18: 1024x1024 (no detections), 20.8ms\n",
      "19: 1024x1024 (no detections), 20.8ms\n",
      "20: 1024x1024 (no detections), 20.8ms\n",
      "21: 1024x1024 (no detections), 20.8ms\n",
      "22: 1024x1024 (no detections), 20.8ms\n",
      "23: 1024x1024 (no detections), 20.8ms\n",
      "Speed: 1.7ms preprocess, 20.8ms inference, 13.0ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 20/21 [00:38<00:01,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 18.0ms\n",
      "1: 1024x1024 (no detections), 18.0ms\n",
      "2: 1024x1024 (no detections), 18.0ms\n",
      "3: 1024x1024 (no detections), 18.0ms\n",
      "Speed: 1.5ms preprocess, 18.0ms inference, 22.9ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:39<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from ultralytics.utils.ops import nms_rotated\n",
    "\n",
    "directory_path = '/workspace/dataset/'\n",
    "# directory_path = './'\n",
    "base_dir = './temp_cropped_patches'\n",
    "img_list = get_imglist(directory_path)\n",
    "# 모델 설정\n",
    "model_name = \"./l_s1024_bgr05_scale084_2.pt\"\n",
    "crop_size = 512\n",
    "resize_size = 1024\n",
    "batch_size = 32\n",
    "model = YOLO(model_name)\n",
    "\n",
    "result = {}  # 최종 결과를 저장할 딕셔너리\n",
    "\n",
    "for image_path in img_list:\n",
    "    # 임시 폴더 생성\n",
    "    temp_dir = create_temp_dir(base_dir=base_dir)\n",
    "    image_name = os.path.basename(image_path)\n",
    "    print(f\"Processing image: {image_name}\")\n",
    "    \n",
    "    # 이미지 크롭 및 임시 폴더에 저장\n",
    "    save_cropped_patches_single_image(image_path, crop_size, temp_dir)\n",
    "    \n",
    "    temp_list = get_imglist(temp_dir)\n",
    "    # 데이터셋 및 DataLoader 설정\n",
    "    dataset = CroppedPatchDataset(temp_list, resize_size=resize_size)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=8)\n",
    "    \n",
    "    # 원본 이미지별 결과 리스트 초기화\n",
    "    result[image_name] = []\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        images = batch['image']\n",
    "        positions = batch['top_left_position']\n",
    "        image_names = batch['image_name']\n",
    "        \n",
    "        # 모델 실행 및 결과 저장\n",
    "        run_model(image_names, images, positions, model, crop_size/resize_size, result)\n",
    "    \n",
    "    # 현재 이미지의 모든 패치 예측을 NMS 적용\n",
    "    per_image_result = result[image_name]\n",
    "    if per_image_result:\n",
    "        # boxes와 scores 추출\n",
    "        boxes = torch.tensor([pred['xywhr'] for pred in per_image_result])\n",
    "        scores = torch.tensor([pred['conf'] for pred in per_image_result])\n",
    "        \n",
    "        # NMS 적용\n",
    "        keep_indices = nms_rotated(boxes, scores, threshold=0.45)\n",
    "        \n",
    "        # NMS 결과를 최종적으로 업데이트\n",
    "        result[image_name] = [per_image_result[i] for i in keep_indices]\n",
    "\n",
    "    # 쿠다 캐시 제거 및 불필요한 메모리 제거\n",
    "    torch.cuda.empty_cache()\n",
    "    del dataset\n",
    "    del dataloader\n",
    "    # 임시 폴더 삭제\n",
    "    shutil.rmtree(temp_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = \n",
    "{'task_smaple.png': [{'xywhr': [tensor(229.2828, device='cuda:0'),\n",
    "    tensor(10279.5654, device='cuda:0'),\n",
    "    tensor(82.1188, device='cuda:0'),\n",
    "    tensor(14.0488, device='cuda:0'),\n",
    "    tensor(1.9125, device='cuda:0')],\n",
    "   'conf': 0.34337615966796875},\n",
    "  {'xywhr': [tensor(151.2560, device='cuda:0'),\n",
    "    tensor(10446.5742, device='cuda:0'),\n",
    "    tensor(110.7664, device='cuda:0'),\n",
    "    tensor(25.3042, device='cuda:0'),\n",
    "    tensor(2.5097, device='cuda:0')],\n",
    "   'conf': 0.27472221851348877},\n",
    "   ...]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# CSV에 저장할 데이터를 담을 리스트\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 이미지 이름별로 데이터 변환\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_name, predictions \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predictions:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "# 저장할 CSV 경로\n",
    "csv_file = \"./submission.csv\"\n",
    "data = []  # CSV에 저장할 데이터를 담을 리스트\n",
    "\n",
    "# 이미지 이름별로 데이터 변환\n",
    "for image_name, predictions in result.items():\n",
    "    if not predictions:\n",
    "        continue\n",
    "    \n",
    "    # 각 예측 결과를 변환하여 data 리스트에 추가\n",
    "    for pred in predictions:\n",
    "        cx, cy, width, height, angle = pred['xywhr']\n",
    "        \n",
    "        # 각도 변환: 라디안 -> 도(degrees)\n",
    "        angle_deg = math.degrees(angle)\n",
    "        if angle_deg < 0:\n",
    "            angle_deg += 360\n",
    "        \n",
    "        # 예측 결과를 리스트로 추가\n",
    "        data.append([image_name, cx, cy, width, height, angle_deg])\n",
    "\n",
    "# CSV 파일로 저장\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # CSV의 헤더 작성\n",
    "    writer.writerow(['image_name', 'cx', 'cy', 'width', 'height', 'angle'])\n",
    "    \n",
    "    # 각 행을 작성\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV 파일 '{csv_file}'이(가) 성공적으로 생성되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file : task.py\n",
      "python\n",
      "제출 완료\n",
      "time: 105.83351588249207\n"
     ]
    }
   ],
   "source": [
    "import aifactory.score as aif\n",
    "import time\n",
    "\n",
    "t = time.time()\n",
    "aif.submit(model_name=\"l_s1024_bgr05_scale084_2\",\n",
    "           key=\"246f41b0-c912-46f5-8f9a-42171aa1f7f0\")\n",
    "print(\"time:\", time.time() - t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
