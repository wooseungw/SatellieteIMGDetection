{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # 이미지 파일이 손상되었을 때 에러 발생 방지\n",
    "\n",
    "def get_imglist(dir=\"./sample/img\"):\n",
    "    imglist = [os.path.join(dir, f).replace(\"\\\\\", \"/\") for f in os.listdir(dir) if f.endswith('.png')]\n",
    "    return imglist\n",
    "\n",
    "class ImagePatchDataset(Dataset):\n",
    "    def __init__(self, image, crop_size, transform=None):\n",
    "        self.image = image\n",
    "        self.crop_size = crop_size\n",
    "        self.transform = transform\n",
    "        self.image_width, self.image_height = image.size\n",
    "\n",
    "        self.num_patches_x = (self.image_width + self.crop_size - 1) // self.crop_size\n",
    "        self.num_patches_y = (self.image_height + self.crop_size - 1) // self.crop_size\n",
    "        self.total_patches = self.num_patches_x * self.num_patches_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_patches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = idx % self.num_patches_x\n",
    "        j = idx // self.num_patches_x\n",
    "        top_left_x = i * self.crop_size\n",
    "        top_left_y = j * self.crop_size\n",
    "        bottom_right_x = min(top_left_x + self.crop_size, self.image_width)\n",
    "        bottom_right_y = min(top_left_y + self.crop_size, self.image_height)\n",
    "\n",
    "        if bottom_right_x - top_left_x < self.crop_size:\n",
    "            top_left_x = max(self.image_width - self.crop_size, 0)\n",
    "            bottom_right_x = self.image_width\n",
    "        if bottom_right_y - top_left_y < self.crop_size:\n",
    "            top_left_y = max(self.image_height - self.crop_size, 0)\n",
    "            bottom_right_y = self.image_height\n",
    "\n",
    "        cropped_image = self.image.crop((top_left_x, top_left_y, bottom_right_x, bottom_right_y))\n",
    "\n",
    "        resize = self.crop_size * 2\n",
    "        cropped_image = cropped_image.resize((resize, resize), resample=Image.Resampling.LANCZOS)\n",
    "\n",
    "        cropped_image_np = np.array(cropped_image)\n",
    "        cropped_image_bgr = cropped_image_np[:, :, ::-1]\n",
    "        cropped_image_pil = Image.fromarray(cropped_image_bgr, 'RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            cropped_image = self.transform(cropped_image_pil)\n",
    "        else:\n",
    "            cropped_image = transforms.ToTensor()(cropped_image_pil)\n",
    "\n",
    "        position = torch.tensor([top_left_x, top_left_y])\n",
    "\n",
    "        return {'image': cropped_image, 'position': position}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import transforms\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import glob\n",
    "\n",
    "# ImageFile.LOAD_TRUNCATED_IMAGES = True  # 이미지 파일이 손상되었을 때 에러 발생 방지\n",
    "# # 이미지 목록을 가져오는 함수\n",
    "# def get_imglist(dir=\"./sample/img\"):\n",
    "#     imglist = [os.path.join(dir, f).replace(\"\\\\\", \"/\") for f in os.listdir(dir) if f.endswith('.png')]\n",
    "#     return imglist\n",
    "\n",
    "# class CroppedImageDataset(Dataset):\n",
    "#     def __init__(self, image_list, crop_size):\n",
    "#         self.image_list = image_list\n",
    "#         self.crop_size = crop_size\n",
    "#         self.transform = transforms.ToTensor()  # 이미지 -> 텐서 변환\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_list)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image_path = self.image_list[idx]\n",
    "#         image_name = os.path.basename(image_path)\n",
    "\n",
    "#         # 이미지 열기\n",
    "#         image = Image.open(image_path).convert('RGB')\n",
    "#         image_width, image_height = image.size\n",
    "#         # # 이미지를 BGR로 변환\n",
    "#         image_np = np.array(image)  # PIL 이미지 -> NumPy 배열\n",
    "#         image_bgr = image_np[:, :, ::-1]  # RGB -> BGR로 색상 채널 순서 변경\n",
    "#         image = Image.fromarray(image_bgr, 'RGB')  # NumPy 배열 -> PIL 이미지\n",
    "#         # 전체 크롭 이미지 개수 계산\n",
    "#         num_crops_x = (image_width + self.crop_size - 1) // self.crop_size\n",
    "#         num_crops_y = (image_height + self.crop_size - 1) // self.crop_size\n",
    "#         total_crops = num_crops_x * num_crops_y\n",
    "\n",
    "#         # 크롭할 영역의 좌상단 좌표를 슬라이딩 윈도우 방식으로 구함\n",
    "#         cropped_images = []\n",
    "#         positions = []\n",
    "#         last_cropped_image_info = None  # 마지막 크롭된 이미지 정보 저장\n",
    "\n",
    "#         for top_left_x in range(0, image_width, self.crop_size):\n",
    "#             for top_left_y in range(0, image_height, self.crop_size):\n",
    "#                 # 마지막 부분에서 경계 넘지 않도록 마지막 부분을 맞춤\n",
    "#                 bottom_right_x = min(top_left_x + self.crop_size, image_width)\n",
    "#                 bottom_right_y = min(top_left_y + self.crop_size, image_height)\n",
    "\n",
    "#                 # 이미지 경계 부분에 대해 크롭 영역을 이동시킴\n",
    "#                 if bottom_right_x - top_left_x < self.crop_size:\n",
    "#                     top_left_x = image_width - self.crop_size\n",
    "#                     bottom_right_x = image_width\n",
    "\n",
    "#                 if bottom_right_y - top_left_y < self.crop_size:\n",
    "#                     top_left_y = image_height - self.crop_size\n",
    "#                     bottom_right_y = image_height\n",
    "\n",
    "#                 # 크롭한 이미지 자르기\n",
    "#                 cropped_image = image.crop((top_left_x, top_left_y, bottom_right_x, bottom_right_y))\n",
    "#                 ############################################################\n",
    "#                 # 크롭한 이미지를 resize\n",
    "#                 resize = self.crop_size * 2\n",
    "#                 cropped_image = cropped_image.resize((resize, resize), resample=Image.Resampling.LANCZOS)\n",
    "#                 ############################################################\n",
    "#                 # 크롭한 이미지를 텐서로 변환\n",
    "#                 cropped_image_tensor = self.transform(cropped_image)\n",
    "\n",
    "#                 # 크롭한 이미지와 좌상단 좌표 저장\n",
    "#                 cropped_images.append(cropped_image_tensor)\n",
    "#                 positions.append(torch.tensor([top_left_x, top_left_y]))\n",
    "\n",
    "#                 # 마지막 크롭된 이미지의 정보 저장 (좌표와 실제 크기)\n",
    "#                 last_cropped_image_info = {\n",
    "#                     'image_tensor': cropped_image_tensor,\n",
    "#                     'top_left': (top_left_x, top_left_y),\n",
    "#                     'bottom_right': (bottom_right_x, bottom_right_y),\n",
    "#                     'size': (bottom_right_x - top_left_x, bottom_right_y - top_left_y)  # 실제 크기 저장\n",
    "#                 }\n",
    "\n",
    "#         # 이미지 이름, 크롭한 이미지 텐서 목록, 각 이미지의 좌상단 좌표 및 크롭 개수 반환\n",
    "#         return {\n",
    "#             'image_name': image_name,\n",
    "#             'images': cropped_images,  # 잘라낸 이미지 텐서 리스트\n",
    "#             'top_left_positions': positions,  # 각 이미지의 좌상단 좌표 리스트\n",
    "#             'total_crops': total_crops,  # 총 크롭 이미지 개수\n",
    "#             'last_cropped_image_info': last_cropped_image_info  # 마지막 크롭 이미지 정보\n",
    "#         }\n",
    "# # 배치 데이터를 처리하는 collate_fn 정의\n",
    "# def collate_fn(batch, batch_size):\n",
    "#     all_image_names = []\n",
    "#     all_images = []\n",
    "#     all_top_left_positions = []\n",
    "#     total_crops = 0  # 전체 크롭 이미지 개수를 추적\n",
    "#     last_cropped_images_info = []  # 마지막 크롭 이미지 정보 추적\n",
    "\n",
    "#     for item in batch:\n",
    "#         image_names = [item['image_name']] * len(item['images'])  # 각 이미지에 같은 이름을 붙임\n",
    "#         all_image_names.extend(image_names)\n",
    "#         all_images.extend(item['images'])  # 이미지를 리스트에 추가\n",
    "#         all_top_left_positions.extend(item['top_left_positions'])  # 좌상단 좌표 추가\n",
    "#         total_crops += item['total_crops']  # 총 크롭 개수 계산\n",
    "#         last_cropped_images_info.append(item['last_cropped_image_info'])  # 마지막 크롭 정보 추가\n",
    "\n",
    "#     # 전체 이미지 목록을 batch_size 크기씩 나눠서 반환\n",
    "#     batch_start = 0\n",
    "#     while batch_start < len(all_images):\n",
    "#         images_batch = torch.stack(all_images[batch_start:batch_start + batch_size])  # batch_size만큼 이미지 묶기\n",
    "#         positions_batch = torch.stack(all_top_left_positions[batch_start:batch_start + batch_size])  # batch_size만큼 좌표 묶기\n",
    "#         names_batch = all_image_names[batch_start:batch_start + batch_size]  # batch_size만큼 이미지 이름 묶기\n",
    "        \n",
    "#         batch_start += batch_size\n",
    "        \n",
    "#         yield {\n",
    "#             'image_names': names_batch,  # 이미지 이름 리스트\n",
    "#             'images': images_batch,  # [batch_size, 3, crop_size, crop_size]\n",
    "#             'top_left_positions': positions_batch,  # [batch_size, 2]\n",
    "#             'total_crops': total_crops,  # 전체 크롭 이미지 개수\n",
    "#             'last_cropped_images_info': last_cropped_images_info  # 마지막 크롭 이미지 정보\n",
    "#         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: task_smaple.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/site-packages/PIL/Image.py:3368: DecompressionBombWarning: Image size (120560400 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/seungwoo/anaconda3/envs/dust/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'ImagePatchDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "# 사용 예시\n",
    "#directory_path = '/workspace/dataset/'\n",
    "directory_path = './'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "crop_size = 224\n",
    "batch_size = 2\n",
    "img_list = get_imglist(directory_path)\n",
    "\n",
    "# color_stats_file = './train_color_stats.npz'\n",
    "\n",
    "####################\n",
    "model_name = \"./yolo11s-obb.pt\"\n",
    "####################\n",
    "# 모델 정의 \n",
    "model = YOLO(model_name)  # YOLO OBB 모델 불러오기\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")  # GPU 또는 MPS 사용\n",
    "\n",
    "# 모델은 이미 내부적으로 GPU/MPS를 사용하므로 입력 이미지를 device로 보냄\n",
    "# dataset = CroppedImageDataset(img_list, crop_size)\n",
    "# dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=lambda x: collate_fn(x, batch_size))\n",
    "\n",
    "\n",
    "\n",
    "for image_path in img_list:\n",
    "    image_name = os.path.basename(image_path)\n",
    "    print(f\"Processing image: {image_name}\")\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    patch_dataset = ImagePatchDataset(image, crop_size, transform=transform)\n",
    "    patch_loader = DataLoader(patch_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    for batch in patch_loader:\n",
    "        images = batch['image']\n",
    "        positions = batch['position']\n",
    "\n",
    "    del image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# YOLO 모델을 사용한 예측 함수\n",
    "def run_yolo_on_images(dataloader, model, device):\n",
    "    results = []  # 예측 결과를 저장할 리스트\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        for sub_batch in batch:  # 각 sub_batch에 대해 처리\n",
    "            images = sub_batch['images'].to(device)  # 이미지를 device로 전송\n",
    "            top_left_positions = sub_batch['top_left_positions'].to(device)  # 좌상단 좌표도 device로 전송\n",
    "            \n",
    "            # YOLO 모델 예측 수행\n",
    "            preds = model.predict(images,conf=0.1,save=True)  # Ultralytics YOLO 모델의 predict 함수 사용\n",
    "\n",
    "            obb = [ pred.obb.xywhr for pred in preds]\n",
    "            conf = [ pred.obb.conf for pred in preds]\n",
    "            results.append({\n",
    "                'image_names': sub_batch['image_names'],\n",
    "                'obb':obb,\n",
    "                'conf':conf,\n",
    "                'top_left_positions': top_left_positions\n",
    "                \n",
    "            })\n",
    "            print(f\"Processed {len(sub_batch['image_names'])} images with predictions.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 모델을 사용한 예측 수행\n",
    "predictions = []\n",
    "predictions += run_yolo_on_images(dataloader, model, device)\n",
    "print(\"예측 완료\")\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일 './submission.csv'이(가) 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "import math\n",
    "import datetime\n",
    "from ultralytics.utils.ops import nms_rotated\n",
    "\n",
    "# END: Add timestamp to the CSV filename\n",
    "# 파일 저장할 CSV 경로\n",
    "csv_file = \"./submission.csv\"\n",
    "\n",
    "# 데이터 샘플 (image_name, cx, cy, width, height, angle 등)\n",
    "data = []\n",
    "\n",
    "\n",
    "# NMS 임계값 (IoU 임계값)\n",
    "nms_threshold = 0.7\n",
    "\n",
    "# 'predictions' 리스트에 있는 각 배치에서 데이터를 추출\n",
    "for i in range(len(predictions)):  # predictions 리스트에서 하나씩 꺼냄\n",
    "    image_name = predictions[i]['image_names']  # 각 배치의 이미지 이름 리스트\n",
    "    obb_list = predictions[i]['obb']  # 각 배치의 obb 리스트\n",
    "    top_left_pos_list = predictions[i]['top_left_positions']  # 각 배치의 top_left_positions 리스트\n",
    "    conf_list = predictions[i]['conf']  # 각 배치의 conf 리스트\n",
    "    # 각 배치에서 이미지별로 순회\n",
    "    for j in range(len(obb_list)):\n",
    "        obb_tensor = obb_list[j]\n",
    "        top_left_pos = top_left_pos_list[j]\n",
    "        conf = conf_list[j]\n",
    "        \n",
    "        # obb_tensor가 비어있지 않은 경우에만 처리\n",
    "        if len(obb_tensor) > 0:\n",
    "            # NMS 처리를 위한 준비\n",
    "            boxes = []\n",
    "            scores = [conf[k].item() for k in range(len(conf))]\n",
    "            \n",
    "            for k in range(len(obb_tensor)):\n",
    "                cx = obb_tensor[k][0].item()/2 + top_left_pos[0].item()\n",
    "                cy = obb_tensor[k][1].item()/2 + top_left_pos[1].item()\n",
    "                width = obb_tensor[k][2].item()/2\n",
    "                height = obb_tensor[k][3].item()/2\n",
    "                angle = obb_tensor[k][4].item()\n",
    "\n",
    "                # 사각형 좌표로 변환 (cx, cy, width, height -> x1, y1, x2, y2)\n",
    "                x1 = cx - width / 2\n",
    "                y1 = cy - height / 2\n",
    "                x2 = cx + width / 2\n",
    "                y2 = cy + height / 2\n",
    "\n",
    "                # 박스와 점수 추가\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                \n",
    "\n",
    "                # NMS 수행\n",
    "                boxes_tensor = torch.tensor(boxes, dtype=torch.float32)\n",
    "                scores_tensor = torch.tensor(scores, dtype=torch.float32)\n",
    "                nms_indices = nms(boxes_tensor, scores_tensor, nms_threshold)\n",
    "                print(\"nms indices 완료.\")\n",
    "                print(len(nms_indices))\n",
    "                \n",
    "                # NMS 후 남은 객체들에 대해 각도 변환 및 데이터 추가\n",
    "            for idx in nms_indices:\n",
    "                cx = obb_tensor[idx][0].item()/2 + top_left_pos[0].item()\n",
    "                cy = obb_tensor[idx][1].item()/2 + top_left_pos[1].item()\n",
    "                width = obb_tensor[idx][2].item()/2\n",
    "                height = obb_tensor[idx][3].item()/2\n",
    "                angle = obb_tensor[idx][4].item()\n",
    "                \n",
    "                # 라디안을 도 단위로 변환\n",
    "                angle_deg = math.degrees(angle)\n",
    "                \n",
    "                # 각도를 0~360도 범위로 변환\n",
    "                if angle_deg < 0:\n",
    "                    angle_deg += 360\n",
    "\n",
    "                # 데이터 추가\n",
    "                data.append([image_name[j], cx, cy, width, height, angle_deg])\n",
    "# CSV 파일로 저장\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # CSV의 헤더 작성\n",
    "    writer.writerow(['image_name', 'cx', 'cy', 'width', 'height', 'angle'])\n",
    "    \n",
    "    # 각 행을 작성\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV 파일 '{csv_file}'이(가) 성공적으로 생성되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
