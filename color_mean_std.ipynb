{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 데이터셋에서 RGB Mean, Std 추출 후 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "색상 정보가 train_color_stats.npz 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# 학습 데이터셋 경로\n",
    "train_paths = ['./datasets/images/train', './datasets/images/val']\n",
    "\n",
    "# 색상 통계 계산을 위한 변수\n",
    "mean_list = []\n",
    "std_list = []\n",
    "\n",
    "# 데이터셋 경로의 모든 이미지를 순회하며 색상 정보 추출\n",
    "for path in train_paths:\n",
    "    for img_name in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # 이미지를 텐서로 변환\n",
    "        image_tensor = transforms.ToTensor()(image)\n",
    "        \n",
    "        # 채널별 평균 및 표준 편차 계산\n",
    "        mean_list.append(image_tensor.mean(dim=(1, 2)).numpy())\n",
    "        std_list.append(image_tensor.std(dim=(1, 2)).numpy())\n",
    "\n",
    "# 전체 이미지의 평균 및 표준 편차 계산\n",
    "mean = np.mean(mean_list, axis=0)\n",
    "std = np.mean(std_list, axis=0)\n",
    "\n",
    "# 색상 정보를 파일로 저장\n",
    "np.savez(\"train_color_stats.npz\", mean=mean, std=std)\n",
    "print(\"색상 정보가 train_color_stats.npz 파일로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균: [0.18371484 0.18895996 0.19103165]\n",
      "표준 편차: [0.1316059  0.12825565 0.12362472]\n"
     ]
    }
   ],
   "source": [
    "color_stats_file = \"train_color_stats.npz\"\n",
    "color_stats = np.load(color_stats_file)\n",
    "mean = color_stats['mean']\n",
    "std = color_stats['std']\n",
    "print(\"평균:\", mean)\n",
    "print(\"표준 편차:\", std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장된 RGB 값 파일 load 후 test dataset에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# 이미지 목록을 가져오는 함수\n",
    "def get_imglist(dir=\"./sample/img\"):\n",
    "    imglist = [os.path.join(dir, f).replace(\"\\\\\", \"/\") for f in os.listdir(dir) if f.endswith('.png')]\n",
    "    return imglist\n",
    "\n",
    "class CroppedImageDataset(Dataset):\n",
    "    def __init__(self, image_list, crop_size, color_stats_file):\n",
    "        self.image_list = image_list\n",
    "        self.crop_size = crop_size\n",
    "        self.transform = transforms.ToTensor()  # 이미지 -> 텐서 변환\n",
    "        \n",
    "        # 색상 통계 정보 불러오기\n",
    "        color_stats = np.load(color_stats_file)\n",
    "        self.mean = color_stats['mean']\n",
    "        self.std = color_stats['std']\n",
    "        self.color_transform = transforms.Normalize(mean=self.mean.tolist(), std=self.std.tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_list[idx]\n",
    "        image_name = os.path.basename(image_path)\n",
    "\n",
    "        # 이미지 열기\n",
    "        image = Image.open(image_path)\n",
    "        image_width, image_height = image.size\n",
    "\n",
    "        # 전체 크롭 이미지 개수 계산\n",
    "        num_crops_x = (image_width + self.crop_size - 1) // self.crop_size\n",
    "        num_crops_y = (image_height + self.crop_size - 1) // self.crop_size\n",
    "        total_crops = num_crops_x * num_crops_y\n",
    "\n",
    "        # 크롭할 영역의 좌상단 좌표를 슬라이딩 윈도우 방식으로 구함\n",
    "        cropped_images = []\n",
    "        positions = []\n",
    "        last_cropped_image_info = None  # 마지막 크롭된 이미지 정보 저장\n",
    "\n",
    "        for top_left_x in range(0, image_width, self.crop_size):\n",
    "            for top_left_y in range(0, image_height, self.crop_size):\n",
    "                # 마지막 부분에서 경계 넘지 않도록 마지막 부분을 맞춤\n",
    "                bottom_right_x = min(top_left_x + self.crop_size, image_width)\n",
    "                bottom_right_y = min(top_left_y + self.crop_size, image_height)\n",
    "\n",
    "                # 이미지 경계 부분에 대해 크롭 영역을 이동시킴\n",
    "                if bottom_right_x - top_left_x < self.crop_size:\n",
    "                    top_left_x = image_width - self.crop_size\n",
    "                    bottom_right_x = image_width\n",
    "\n",
    "                if bottom_right_y - top_left_y < self.crop_size:\n",
    "                    top_left_y = image_height - self.crop_size\n",
    "                    bottom_right_y = image_height\n",
    "\n",
    "                # 크롭한 이미지 자르기\n",
    "                cropped_image = image.crop((top_left_x, top_left_y, bottom_right_x, bottom_right_y))\n",
    "\n",
    "                # 크롭한 이미지를 텐서로 변환\n",
    "                cropped_image_tensor = self.transform(cropped_image)\n",
    "                normalized_image_tensor = self.color_transform(cropped_image_tensor)\n",
    "\n",
    "                # 크롭한 이미지와 좌상단 좌표 저장\n",
    "                cropped_images.append(normalized_image_tensor)\n",
    "                positions.append(torch.tensor([top_left_x, top_left_y]))\n",
    "\n",
    "                # 마지막 크롭된 이미지의 정보 저장 (좌표와 실제 크기)\n",
    "                last_cropped_image_info = {\n",
    "                    'image_tensor': normalized_image_tensor,\n",
    "                    'top_left': (top_left_x, top_left_y),\n",
    "                    'bottom_right': (bottom_right_x, bottom_right_y),\n",
    "                    'size': (bottom_right_x - top_left_x, bottom_right_y - top_left_y)  # 실제 크기 저장\n",
    "                }\n",
    "\n",
    "        # 이미지 이름, 크롭한 이미지 텐서 목록, 각 이미지의 좌상단 좌표 및 크롭 개수 반환\n",
    "        return {\n",
    "            'image_name': image_name,\n",
    "            'images': cropped_images,  # 잘라낸 이미지 텐서 리스트\n",
    "            'top_left_positions': positions,  # 각 이미지의 좌상단 좌표 리스트\n",
    "            'total_crops': total_crops,  # 총 크롭 이미지 개수\n",
    "            'last_cropped_image_info': last_cropped_image_info  # 마지막 크롭 이미지 정보\n",
    "        }\n",
    "\n",
    "# 배치 데이터를 처리하는 collate_fn 정의\n",
    "def collate_fn(batch, batch_size):\n",
    "    all_image_names = []\n",
    "    all_images = []\n",
    "    all_top_left_positions = []\n",
    "    total_crops = 0  # 전체 크롭 이미지 개수를 추적\n",
    "    last_cropped_images_info = []  # 마지막 크롭 이미지 정보 추적\n",
    "\n",
    "    for item in batch:\n",
    "        image_names = [item['image_name']] * len(item['images'])  # 각 이미지에 같은 이름을 붙임\n",
    "        all_image_names.extend(image_names)\n",
    "        all_images.extend(item['images'])  # 이미지를 리스트에 추가\n",
    "        all_top_left_positions.extend(item['top_left_positions'])  # 좌상단 좌표 추가\n",
    "        total_crops += item['total_crops']  # 총 크롭 개수 계산\n",
    "        last_cropped_images_info.append(item['last_cropped_image_info'])  # 마지막 크롭 정보 추가\n",
    "\n",
    "    # 전체 이미지 목록을 batch_size 크기씩 나눠서 반환\n",
    "    batch_start = 0\n",
    "    while batch_start < len(all_images):\n",
    "        images_batch = torch.stack(all_images[batch_start:batch_start + batch_size])  # batch_size만큼 이미지 묶기\n",
    "        positions_batch = torch.stack(all_top_left_positions[batch_start:batch_start + batch_size])  # batch_size만큼 좌표 묶기\n",
    "        names_batch = all_image_names[batch_start:batch_start + batch_size]  # batch_size만큼 이미지 이름 묶기\n",
    "        \n",
    "        batch_start += batch_size\n",
    "        \n",
    "        yield {\n",
    "            'image_names': names_batch,  # 이미지 이름 리스트\n",
    "            'images': images_batch,  # [batch_size, 3, crop_size, crop_size]\n",
    "            'top_left_positions': positions_batch,  # [batch_size, 2]\n",
    "            'total_crops': total_crops,  # 전체 크롭 이미지 개수\n",
    "            'last_cropped_images_info': last_cropped_images_info  # 마지막 크롭 이미지 정보\n",
    "        }\n",
    "\n",
    "# 사용 예시\n",
    "directory_path = '/workspace/dataset'\n",
    "crop_size = 1024  # 크롭할 이미지의 크기\n",
    "img_list = get_imglist(directory_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
